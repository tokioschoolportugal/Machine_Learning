{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear: Normalização\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Criar um dataset sintético com características em diferentes intervalos de valores\n",
    "- Formar um modelo de regressão linear sobre o dataset original\n",
    "- Normalizar o dataset original\n",
    "- Formar outro modelo de regressão linear sobre o dataset normalizado\n",
    "- Comparar a formação de ambos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do dataset sintético\n",
    "\n",
    "Vamos criar de novo um dataset sintético para regressão linear pelo método manual. \n",
    "\n",
    "Criar um dataset sintético com um termo de erro do 10% do valor de *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copiar o código de exercícios anteriores para gerar um dataset, com termo de bias e erro\n",
    "\n",
    "m = 1000\n",
    "n = 4\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.1\n",
    "\n",
    "Y = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprovar os valores e dimensões dos vetores\n",
    "\n",
    "print('Theta a estimar e as suas dimensões') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos modificar o dataset para assegurar que cada característica, cada coluna de X, tem uma ordem de magnitude e uma média diferente.\n",
    "\n",
    "Para isso, multiplicar cada coluna de X (exceto a primeira, o bias) por um intervalo e somar um valor diferente. O valor que somarmos será a media dessa característica ou coluna.\n",
    "\n",
    "P. ex., $X_1 = X_1 * 10^3 + 3.1415926$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para cada coluna de X, multiplicar por um intervalo de valores e adicionar uma média diferente.\n",
    "\n",
    "# As séries de intervalos e médias têm de ser de comprimento n\n",
    "# Criar um array com as gamas de valores, por exemplo: 1e0, 1e3, 1e-2, 1e5\n",
    "rangos = [...]\n",
    "\n",
    "medias = [...]\n",
    "\n",
    "X = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar os novos valores de X, pode voltar a executar a célula com o código para os imprimir.\n",
    "\n",
    "Recordar que pode executar as células Jupyter numa ordem diferente da sua posição no documento. Os parênteses retos à esquerda das células irão marcar a ordem de execução, e as variáveis irão manter sempre os seus valores após a última célula executada, por isso **tenha cuidado!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formação e avaliação do modelo\n",
    "\n",
    "Vamos voltar a formar um modelo de regressão linear. Desta vez, vamos formar primeiro no dataset original, sem normalizar, e depois voltar a formá-lo no dataset normalizado, para comparar ambos os modelos e processos de formação e ver os efeitos da normalização.\n",
    "\n",
    "Para tal, deve copiar as células ou código de exercícios anteriores e formar um modelo de regressão linear multivariável, otimizado por gradient descent, no subset original.\n",
    "\n",
    "Deve também copiar as células que comprovam a formação do modelo, representando a função custo vs. o número de iterações.\n",
    "\n",
    "Não é necessário fazer previsões sobre estes dados nem avaliar os resíduos do modelo. Para os comparar, iremos fazer apenas através do custo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo de regressão linear e representar graficamente a sua função de custo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização dos dados\n",
    "\n",
    "Vamos normalizar os dados do dataset original.\n",
    "\n",
    "Para tal, vamos criar uma função de normalização que aplica a transformação necessária, de acordo com a fórmula:\n",
    "\n",
    "$x = \\frac{x - \\mu_{x_j}}{\\sigma_{x_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar uma função de normalização a um intervalo comum e com média 0\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normalizar um dataset com exemplos X\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os exemplos, sem termo de bias\n",
    "    mu -- vetor 1D de Numpy com a média de cada característica/coluna\n",
    "    std -- vetor 1D de Numpy com o desvio típico de cada característica/coluna\n",
    "    \n",
    "    Devolver:\n",
    "    X norm -- array 2D de Numpy com os exemplos, com as suas características normalizadas \n",
    "    \"\"\"\n",
    "    return [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar o dataset original usando a sua função de normalização.\n",
    "\n",
    "# Encontrar a média e o desvio padrão das características de X (colunas), exceto a primeira (parcialidade).\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Média e desvio típico das características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normalizar apenas a coluna 1 e as colunas seguintes, \n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-formação do modelo e comparação de resultados\n",
    "\n",
    "Agora, voltar a formar o modelo no dataset normalizado. Comprovar o custo final e a iteração onde convergiu.\n",
    "\n",
    "Para tal, pode voltar às células de formação do modelo e verificar a evolução da função custo e modificar o X utilizado por X_norm.\n",
    "\n",
    "Em muitos casos, sendo um modelo tão simples, pode não se ver qualquer melhoria. Em função da capacidade do seu ambiente, tente utilizar um número maior de características e aumentar ligeiramente o termo de erro do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuidado com o Theta original\n",
    "\n",
    "Para o dataset original, antes de o normalizar, cumprir a relação $Y = X \\times \\Theta$.\n",
    "\n",
    "No entanto, agora modificámos o X dessa função.\n",
    "\n",
    "Portanto, comprovar o que acontece se quiser voltar a computar *Y* usando o *X* normalizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Comprovar se existem diferenças entre o Y original e o Y usando X normalizado\n",
    "\n",
    "# Comprovar o valor de Y ao multiplicar X_norm e Theta_verd\n",
    "Y_norm = [...]\n",
    "\n",
    "# Comprovar se há diferenças entre Y_norm e Y\n",
    "diff = Y_norm - Y\n",
    "\n",
    "print('Diferenças entre Y_norm e Y:') \n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazer previsões\n",
    "\n",
    "Da mesma forma, o que acontece quando vamos utilizar o modelo para fazer previsões?\n",
    "\n",
    "Gerar um novo conjunto de dados X_pred seguindo o mesmo método que usou para o dataset original X, incorporando o termo de bias, multiplicando as suas características por um intervalo e acrescentando-lhes valores diferentes.\n",
    "\n",
    "Da mesma forma, calcular o seu Y_pred_verd (sem termo de erro):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um novo dataset com menos exemplos e o mesmo número de características que o dataset original.\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "Y_pred_verd = np.matmul(X_pred, Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora comprovar se haveria alguma diferença entre o *Y_pred_verd* e o *Y_pred* que o seu modelo iria prever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprovar as diferenças entre o Y real e o Y prevista\n",
    "\n",
    "Y_pred = np.matmul(X_pred, theta)\n",
    "\n",
    "print('Diferenças entre Y real e Y previsto:') \n",
    "print(Y_pred_verd - Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que as previsões não são corretas, deveríamos previamente normalizar a nova *X_pred*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar a X_pred\n",
    "\n",
    "X_pred[...] = normalize(X_pred[...], mu, std) \n",
    "\n",
    "print(X_pred)\n",
    "print(X_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez não gerámos uma nova variável diferente ao normalizar, mas continua a ser a variável *X_pred*.\n",
    "\n",
    "Assim, pode voltar a executar as células anteriores para, agora que o *X_pred* está normalizado, comprovar se existe alguma diferença entre o *Y* real e o *Y* previsto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por isso, recordar sempre:\n",
    "- O *Theta* calculado na formação do modelo será sempre relativo ao dataset normalizado, e não pode ser utilizado para o dataset original, uma vez que é igual a *Y* e diferente de *X*, o *Theta* deve mudar.\n",
    "- Para fazer previsões sobre novos exemplos, temos primeiro de os normalizar também, usando os mesmos valores de meios e desvios padrão que usámos originalmente para formar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
