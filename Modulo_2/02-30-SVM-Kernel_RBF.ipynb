{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Kernel RBF\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Gerar um dataset sintético de 2 classes (binário). \n",
    "- Pré-processar o dataset.\n",
    "- Formar um modelo de classificação por SVM sobre o mesmo. \n",
    "- Comprovar a sua adequação.\n",
    "- Otimizar os hiper-parâmetros do nosso modelo por validação cruzada. \n",
    "- Avaliar o nosso modelo.\n",
    "\n",
    "Da mesma forma que tínhamos feito para a classificação de regressão logística usando Scikit-learn, vamos agora usar este quadro para resolver problemas de classificação SVM.\n",
    "\n",
    "Em concreto, vamos usar o seu classificador SVC com o núcleo RBF (“Radial Basis Function”). O modelo Scikit-learn SVC tem uma série de núcleos disponíveis, e em particular, o núcleo gaussiano não está entre eles. Contudo, este núcleo RBF está intimamente relacionado, uma vez \n",
    "que também parte de uma classificação “radial”, e em projetos reais é uma implementação que pode ser mais eficiente e ter melhor desempenho do que o kernel Gaussiano, mais simples.\n",
    "\n",
    "\n",
    "Por conseguinte, em vez do núcleo gaussiano, vamos usar a RBF. Este kernel para SVM tem 2 parâmetros:\n",
    "\n",
    "- *C*: O inverso do parâmetro de regularização. Para valores maiores de *C*, será aceite uma margem menor entre classes se a função de decisão classificar melhor os exemplos de formação. Valores mais baixos de *C* irão tentar aumentar a margem entre classes, com uma função de decisão mais simples e, portanto, à custa de uma eventual menor precisão.\n",
    "- *Gamma*: Define até onde chega a influência de cada exemplo, ou o inverso do raio de influência dos exemplos selecionados pelo modelo como landmarks. Valores mais baixos significarão uma influência que chega mais longe, e valores mais altos significarão uma influência que chega muito menos longe.\n",
    "\n",
    "Vamos otimizar ambos os parâmetros usando a validação cruzada.\n",
    "\n",
    "Como referência para este exercício, pode utilizar estas ligações a partir da documentação:\n",
    "- [SVM: Classification](https://scikit-learn.org/stable/modules/svm.html#classification)\n",
    "- [skelarn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "- [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "- [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html)\n",
    "- [Non-linear SVM](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_nonlinear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar de todos os módulos necessários para esta célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar um dataset sintético de classificação binária\n",
    "\n",
    "Criar um dataset para classificação de 2 classes com [sklearn.datasets.make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html).\n",
    "\n",
    "Recordar utilizar parâmetros que podemos então modificar para o número de exemplos, características e classes, se queremosque não seja ordenado ou não, um estado inicial aleatório constante, etc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Criar um dataset sintético para classificação binária"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados:\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizar.\n",
    "- Dividir em subsets de formação e test (usar CV por K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os dados se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação, CV e testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo de classificação por SVM inicial\n",
    "\n",
    "Para comprovar o funcionamento do nosso classificador SVC antes de o otimizar por validação cruzada, vamos formar um modelo inicial sobre o subset de formação e validá-lo sobre o subset de teste\n",
    "\n",
    "Recordar usar a função [decision_function_shape](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification)  para usar o esquema “um contra o resto” (“ovr”). \n",
    "\n",
    "Usar os valores por defeito de *C* e *gamma* para não influir sobre a sua regularização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo de SVC sem modificar os parâmetros de regularização sobre o subset de formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com o seu score () no subset de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma muito gráfica para compreender melhor como funcionam as SVMs e de verificar a precisão do seu modelo é representar o híper-plano que agora separa as classes, cuja margem com as classes estamos a tentar maximizar.\n",
    "\n",
    "Para o representar, recordar que pode seguir o exemplo da [SVM: Maximum margin separating hyperplane](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html)  e modificar o seu código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente o hiper-plano de separação com a margem de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizar os hiper-parâmetros de regularização por validação cruzada\n",
    "\n",
    "Agora vamos usar novamente o [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)  para otimizar os nossos hiper-parâmetros *C* e *gamma* por K-fold. \n",
    "\n",
    "Queremos otimizar esses parâmetros, 2 de cada vez, e representar os seus possíveis valores de uma forma visual.\n",
    "\n",
    "Um exemplo muito interessante que referenciávamos é [RBF SVM parameters](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
    "\n",
    "Modificar o seu código para otimizar o nosso modelo no nosso dataset sintéticos utilizando o K-fold para otimizar o *C* e o *gamma*. Pode usar o mesmo intervalo logarítmico de valores para estes hiper-parâmetros propostos no exercício ou modificá-los para encontrar um adequado para o seu dataset sintético.\n",
    "\n",
    "*Nota*: Recordar que já processamos previamente o dataset seguindo os nossos métodos habituais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Otimizar os hiper-parâmetros de SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: por vezes é uma boa ideia dividir o código em diferentes células, de modo a poder modificá-las e voltar a executá-las independentemente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar os efeitos dos parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo finalmente sobre o subset de teste\n",
    "- Mostrar os coeficientes e intercept do melhor modelo. \n",
    "- Avaliar o melhor modelo sobre o subset de teste inicial.\n",
    "- Representar as previsões das classes para verificar os acertos, falhas e a margem entre classes no novo hiper-plano.\n",
    "\n",
    "Para representar as previsões e o hiper-plano de margem entre classe, pode reutilizar o código com o qual avaliou o modelo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o melhor modelo sobre o subset de teste inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar as previsões, comprovar a precisão e a margem entre classes"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
