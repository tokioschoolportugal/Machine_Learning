{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística: Dataset Iris\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Descarregar e analisar o dataset Iris.\n",
    "- Pré-processar o dataset.\n",
    "- Formar um modelo de classificação sobre o mesmo. \n",
    "- Otimizar o nosso modelo por validação cruzada.\n",
    "\n",
    "O dataset Iris é um dos mais conhecidos e utilizados em ML. Usamos habitualmente como exemplo para explicar algoritmos de modelos, e também se usa amplamente para comparar vários modelos entre si, em função da sua precisão no mesmo.\n",
    "\n",
    "Pode conhecer mais sobre este dataset na Wikipedia: [Conjuntos de datos flor iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris)\n",
    "\n",
    "Pode encontrar este modelo em Scikit-learn como [dataset de ejemplo](https://scikit-learn.org/stable/datasets/index.html#iris-dataset) e carregá-lo com a função [sklearn.datasets.load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html).\n",
    "\n",
    "Neste exercício vai continuar os mesmos passos do último exercício para resolver um modelo de classificação de 3 classes, neste caso sobre um dataset real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar todos os módulos necessários para esta célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o dataset Iris\n",
    "\n",
    "Carregar o dataset e analisar alguns dos exemplos para conhecer mais sobre ele\n",
    "\n",
    "Pode ser que seja interessante representá-los graficamente como neste exercício: [The Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Carregar o dataset Iris como arrays X e Y\n",
    "# Comprovar em que formato está codificado Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Pré-processar os dados seguindo os passos habituais.\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizá-los, apenas se necessário.\n",
    "- Dividi-los em subsets de formação, CV e testes\n",
    "\n",
    "*Nota*: Cuidado na altura de os dividir em subsets, *quantos exemplos tem o dataset original?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os dados se necessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividi-los em subsets de formação, CV e testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar a função de ativação sigmoide, a função de custo regularizada e a função de formação por gradient descent regularizado\n",
    "\n",
    "Copiar o código de exercícios anteriores para implementar essas funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar a função sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar as funções de custo e gradient descent regularizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo inicial em cada classe\n",
    "\n",
    "Para garantir que a sua implementação funciona bem com o formato do datasets, formar um modelo inicial simples para cada classe sem regularização.\n",
    "\n",
    "Comprovar se a sua implementação funciona bem com o formato do dataset. Se necessário, modificar o dataset para que o possa usar com o seu código\n",
    "\n",
    "Modificar os parâmetros de formação e voltar a formá-los, se necessário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar os seus modelos no subset de formação sem regularizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar o hiper-parâmetro *lambda* ótimo por CV\n",
    "\n",
    "Depois de termos formado o modelo inicial, e visto o seu desempenho, vamos formar um modelo para cada uma das 3 classes, com vários valores de lambda, como em exercícios anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo para cada valor lambda diferente para cada uma das classes e avaliá-lo em X_c\n",
    "# Os valores de lambda que considerámos anteriormente eram:\n",
    "# lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "# Se preferir, modificar o número de valores lambda para não formar tantos modelos e demorar tanto tempo.\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente o erro final para cada valor de lambda com um gráfico por classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolher o melhor modelo para cada classe\n",
    "\n",
    "Copiar as células de código de exercícios anteriores e modificá-las se é necessário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escolher os modelos e o valores lambda ótimos para cada classe sobre o subset do CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar os modelos sobre o subset de teste\n",
    "\n",
    "Uma vez formados os modelos, avaliá-los no subset de teste.\n",
    "\n",
    "Neste caso, vamos fazer uma avaliação final mais completa. Em vez de avaliar os 3 modelos separadamente, apenas com o Y que cada modelo iria ver, fazer previsões sobre o subset de teste da mesma forma que fez na última secção do exercício anterior (“Fazer previsões sobre novos exemplos”): ou seja, para todo o subset de teste, fazer uma previsão para cada modelo de cada classe e escolher o que tiver o resultado mais elevado.\n",
    "\n",
    "Além disso, adicionar uma nova modificação: ao escolher a classe com o valor mais elevado após o sigmoide, apenas escolher classes cujo sigmoide é >= 0,5, visto que por vezes os 3 modelos podem prever valores de 0,1, 0,2, 0,25, etc., que estão realmente a prever que o exemplo não cai em nenhuma das suas 3 classes.\n",
    "\n",
    "Com estas previsões, calcular os resíduos e representá-los graficamente.\n",
    "\n",
    "Desta forma, estamos a avaliar o nosso modelo face a um ambiente muito mais realista, utilizando também um dataset real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular o erro do modelo com os resíduos sobre o subset de teste e representá-los graficamente"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
