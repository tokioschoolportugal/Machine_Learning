{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear: Exemplo sobre dataset sintético\n",
    "\n",
    "## O que vamos fazer?\n",
    "\n",
    "- Usar um dataset sintético gerado automaticamente para comprovar a nossa implementação \n",
    "- Formar um modelo ML de regressão linear multivariável\n",
    "- Comprovar a evolução da formação do modelo \n",
    "- Avaliar o modelo de uma forma simples\n",
    "- Fazer previsões sobre novos exemplos futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do dataset sintético\n",
    "\n",
    "Vamos criar um dataset sintético para comprovar a nossa implementação.\n",
    "\n",
    "Segundo os métodos que usámos em exercícios anteriores, criar um dataset sintéticos usando o método Numpy.\n",
    "\n",
    "Incluir um termo de erro controlável nesse dataset mas iniciar a 0, uma vez que para fazer a primeira implementação deste modelo ML de regressão linear multivariável queremos que não haja nenhum erro nos dados que possam ocultar um erro no nosso modelo.\n",
    "\n",
    "Mais tarde vamos introduzir um termo de erro com um valor distinto de zero, para comprovar que a nossa implementação pode \n",
    "também formar o modelo nestas circunstâncias mais reais.\n",
    "\n",
    "### O termo de bias ou intercept\n",
    "\n",
    "Desta vez, vamos gerar o dataset sintético com uma pequena modificação: vamos adicionar uma primeira coluna de 1s a X, ou um 1 \n",
    "como primeiro valor das características de cada exemplo.\n",
    "\n",
    "Além disso, uma vez que adicionamos mais uma característica à matriz X, adicionamos mais uma característica ou valor ao vetor Theta.\n",
    "\n",
    "Porque é que adicionamos esta coluna, este novo termo ou característica?\n",
    "\n",
    "Porque é a forma mais simples de implementar a equação linear numa única operação de álgebra linear\n",
    "\n",
    "Desta forma convertemos então $Y = m \\times X + b$ en $Y = X \\times \\Theta$, poupando-nos uma operação de soma e implementando a equação numa única operação de multiplicação da matriz.\n",
    "\n",
    "O termo b é, portanto, incorporado como o primeiro termo do vetor Theta, que quando multiplicado pela primeira coluna de X, sendo de valor 1 para todas as linhas, permite-nos adicionar o termo b a cada exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um dataset sintético, com termo de erro inicialmente a 0, sob a forma que escolher\n",
    "\n",
    "m = 100\n",
    "n = 3\n",
    "\n",
    "# Criar uma matriz de números aleatórios no intervalo [-1, 1)\n",
    "X = [...]\n",
    "\n",
    "# Inserir um vetor de 1s como primeira coluna de X\n",
    "# Dicas: np.insert(), np.ones(), índice 0, eixo 1...\n",
    "X = [...]\n",
    "\n",
    "# Gerar um vetor de números aleatórios no intervalo [0, 1) de tamanho n + 1 (ao adicionar o termo bias\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Gerar o vetor Y com um termo de erro aleatório em %, inicializado a 0\n",
    "error = 0.\n",
    "\n",
    "Y = np.matmul(X, Theta_verd) \n",
    "Y = Y + [...]\n",
    "\n",
    "# Verificar os valores e dimensões dos vetores\n",
    "print('Theta a estimar e as suas dimensões') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixar-se na operação de multiplicação da matriz implementada: $Y = X \\times \\Theta$\n",
    "\n",
    "Comprovar as dimensões de cada vetor: X, Y, Theta. \n",
    "\n",
    "Acredita que é uma operação possível em termos das regras da álgebra linear?\n",
    "\n",
    "E ainda assim, foi possível fazê-lo em Numpy? Se tiver dúvidas, pode consultar a documentação Numpy sobre a função np.matmul.\n",
    "\n",
    "Comprovar o resultado, talvez reduzindo o número original de exemplos e características, e assegurar-se de que é um resultado correto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cópia do exercício anterior, a sua implementação da função de custos e a sua otimização por gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copiar o código das suas funções de custo e descida do gradiente\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "    \n",
    "    \"\"\" Computar a função de custo para o dataset e coeficientes considerados.\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "     x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila)\n",
    "    \n",
    "    Devolver:\n",
    "     j -- float com o custo para esse array theta \n",
    "     \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, e, iter_):\n",
    "    \n",
    "    \"\"\" Formar o modelo otimizando a sua função de custo por gradient descent\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpu com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila) \n",
    "    alpha -- float, ratio de formação\n",
    "    \n",
    "    Argumentos numerados (keyword):\n",
    "    e -- float, diferença mínima entre iterações para declarar que a formação finalmente convergiu \n",
    "    iter_ -- int/float, número de iterações\n",
    "    \n",
    "    Devolver:\n",
    "    j_hist -- list/array com a evolução da função de custo durante a formação \n",
    "    theta -- array Numpy com o valor do theta na última iteração\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar estas funções para formar o nosso modelo ML. \n",
    "\n",
    "Recordamos os passos que vamos seguir:\n",
    "- Iniciar theta com valores aleatórios\n",
    "- Otimizar theta reduzindo o custo associado a cada iteração dos seus valores.\n",
    "- Quando tivermos encontrado o valor mínimo da função de custo, tomar o theta associado como os coeficientes do nosso modelo.\n",
    "\n",
    "Portanto, completar o código na seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar o seu modelo ML otimizando os seus coeficientes theta por gradient descent\n",
    "\n",
    "# Inicializar theta com n + 1 valores aleatórios\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:') \n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1 \n",
    "e = 1e-4 \n",
    "iter_ = 1e5\n",
    "\n",
    "print('Hiper-parâmetros a utilizar:') \n",
    "\n",
    "t = time.time()\n",
    "j_hist, theta = gradient_descent([...])\n",
    "\n",
    "print('Tempo de formação (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores da função de custo') \n",
    "print(j_hist[...])\n",
    "print('\\Custo final:') \n",
    "print(j_hist[...]) \n",
    "print('\\nTheta final:') \n",
    "print(theta)\n",
    "\n",
    "print('Valores verdadeiros de Theta e diferença com valores formados:') \n",
    "print(Theta_verd)\n",
    "print(theta - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprovar que não se modificou a Theta inicial. A sua implementação deve copiar um novo objeto Python em cada iteração e não o \n",
    "modificar durante a formação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprovar que não se modificou a Theta inicial\n",
    "\n",
    "print('Theta inicial e theta final:') \n",
    "print(theta_ini)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprovar a formação do modelo\n",
    "\n",
    "Para comprovar a formação do modelo, vamos representar graficamente a evolução da função de custo, para verificar que não houve \n",
    "qualquer grande salto e que este avançou firmemente para um valor mínimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar a evolução da função de custo vs. o número de iterações\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Função de custo') \n",
    "plt.xlabel('Iterações') \n",
    "plt.ylabel('Custo')\n",
    "\n",
    "plt.plot([...]) # Completar a função\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazer previsões\n",
    "\n",
    "Vamos utilizar o theta, o resultado do nosso processo de formação modelo, para fazer previsões sobre novos exemplos que virão no futuro.\n",
    "\n",
    "Vamos gerar um novo conjunto de dados X seguindo os mesmos passos que os acima referidos. Portanto, se X tiver o mesmo número de características e os seus valores estiverem na mesma gama que o X gerado anteriormente, irá comportar-se da mesma forma que os dados utilizados para formar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fazer previsões utilizando o theta calculado.\n",
    "\n",
    "# Gerar uma nova matriz X com novos exemplos. Utilizar o mesmo número de características e a mesma gama de valores aleatórios, mas um número menor de exemplos (por exemplo, 25% do original).\n",
    "# mas um número menor de exemplos (por exemplo, 25% do original).\n",
    "# Recordar de acrescentar o termo bias, ou uma primeira coluna de 1s à matriz.\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Calcular as previsões para estes novos dados\n",
    "y_pred = [...] # Pista: matmul\n",
    "\n",
    "\n",
    "print('Previsões:')\n",
    "print(y_pred)    # Vamos imprimir todos os valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo\n",
    "\n",
    "Há várias opções para avaliar o modelo. Neste momento, vamos fazer uma avaliação mais simples, mais rápida e mais informal do \n",
    "modelo. Nos próximos módulos do curso veremos como avaliar os nossos modelos de uma forma mais formal e precisa.\n",
    "\n",
    "Faremos uma avaliação gráfica, para simplesmente verificar se a nossa implementação está a funcionar como esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar os valores do Y inicial vs X, e o Y previsto para o mesmo vs X.\n",
    "\n",
    "# Realizar previsões para cada valor do X original com o theta formado pelo modelo.\n",
    "Y_pred = [...] \n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title('Dataset original e previsões') \n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "# Usar um gráfico de pontos com cores diferentes para o Y inicial e o Y previsto.\n",
    "plt.scatter([...])\n",
    "plt.scatter([...]) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representar também a diferença em valor absoluto entre o Y original e o Y previsto. \n",
    "\n",
    "Vamos chamar a esta diferença os **resíduos** do nosso modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Calcular e fazer um gráfico dos resíduos do seu modelo no dataset de formação.\n",
    "\n",
    "resíduos = [...] \n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title('Dataset original e previsões') \n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Resíduos') \n",
    "\n",
    "plt.plot(resíduos) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se a nossa implementação estiver correta, o nosso modelo deveria ter sido capaz de formar corretamente e ter um resíduo quase nulo, uma diferença quase nula entre os resultados originais (Y) e os resultados que o nosso modelo iria calcular.\n",
    "\n",
    "Contudo, como nos lembramos, no primeiro ponto criámos um conjunto de dados com o termo de erro a 0. Portanto, cada valor de Y \n",
    "não tem nenhuma diferença ou variação aleatória em relação ao seu verdadeiro valor.\n",
    "\n",
    "Na vida real, ou porque não tivemos em conta todas as características que iriam afetar a nossa variável alvo, ou porque os dados contêm algum pequeno erro, ou porque, em geral, os dados não seguem um comportamento completamente preciso, teremos sempre algum termo de erro, mais ou menos aleatório.\n",
    "\n",
    "Então, e se voltar à primeira célula e modificar o seu termo de erro, e executar novamente as seguintes células para formar e avaliar um novo modelo de regressão linear sobre dados mais próximos da realidade?\n",
    "\n",
    "Verifique a robustez da sua implementação desta forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
