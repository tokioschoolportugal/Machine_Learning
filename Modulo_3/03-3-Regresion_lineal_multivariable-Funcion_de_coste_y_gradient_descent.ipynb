{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear multivariável: Função de custo e gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que vamos fazer?\n",
    "\n",
    "- Implementar a função de custo para regressão linear multivariável \n",
    "- Implementar a otimização da função de custo por gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 1: Implementar a função de custo para regressão linear multivariável\n",
    "\n",
    "Nesta tarefa, deve implementar a função de custo para regressão linear multivariável em Python usando o Numpy. A função de \n",
    "custo deve seguir a função incluída nos diapositivos e no manual do curso.\n",
    "\n",
    "Para o fazer, preencher o código na seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Implementar a função de custo utilizando o seguinte modelo\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "        \"\"\" Computar a função de custo para o dataset e coeficientes considerados.\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila)\n",
    "    \n",
    "        Devolver:i -- float com o custo para esse array theta \n",
    "        \"\"\"\n",
    "        m = [...]\n",
    "\n",
    "        # Recordar de verificar as dimensões da multiplicação da matriz para fazer corretamente.\n",
    "        j = [...]\n",
    "\n",
    "        return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar a sua implementação, recuperar o seu código do notebook anterior sobre datasets sintéticos e seguir as \n",
    "instruções abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um dataset sintético, sem termo de erro, sob a forma que escolher\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "Y = [...]\n",
    "\n",
    "# Comprovar os valores e dimensões (forma ou \"shape\") dos vetores\n",
    "print('Theta a estimar') \n",
    "print()\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print('shape', 'shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que o dataset sintético não tem termo de erro, a função de custo para o theta correto deve ser exatamente 0, aumentando \n",
    "o seu valor à medida que nos afastamos do mesmo.\n",
    "\n",
    "Comprovar a sua implementação da função de custo comprovando o seu valor com diferentes valores do seu argumento theta, \n",
    "comprovando vários valores desde o Theta errado até valores mais afastados do mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Comprovar a implementação da sua função de custos\n",
    "\n",
    "theta = Theta_verd    # Modificar e testar vários valores do theta\n",
    "\n",
    "j = cost_function(X, Y, theta)\n",
    "\n",
    "print('Custo do modelo:') \n",
    "print(j)\n",
    "print('Theta comprovado e Theta real:') \n",
    "print(theta)\n",
    "print(Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2: Implementar a otimização desta função de custo por gradient descent\n",
    "\n",
    "Agora vamos resolver a otimização dessa função de custo para formar o modelo, mediante o método de gradient descent. O \n",
    "modelo será considerado formado quando a sua função de custo tiver atingido um valor mínimo.\n",
    "\n",
    "Para o fazer, preencher novamente o modelo do código na seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar a função que forma o modelo por gradient descent\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, e, iter_):\n",
    "    \n",
    "    \"\"\" Formar o modelo otimizando a sua função de custo por gradient descent\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os valores das variáveis independentes dos exemplos, de tamanho m x n \n",
    "    y -- array 1D Numpy com a variável dependente/objetivo, de tamanho m x 1\n",
    "    theta -- array 1D Numpy com os pesos dos coeficientes do modelo, de tamanho 1 x n (vetor fila) \n",
    "    alpha -- float, ratio de formação\n",
    "    \n",
    "    Argumentos numerados (keyword):\n",
    "    e -- float, diferença mínima entre iterações para declarar que a formação finalmente convergiu \n",
    "    iter_ -- int/float, número de iterações\n",
    "    \n",
    "    Devolver:\n",
    "    j_hist -- list/array com a evolução da função de custo durante a formação \n",
    "    theta -- array Numpy com o valor do theta na última iteração\n",
    "    \"\"\"\n",
    "    # TODO: declarar valores por defeito para e e iter_ nos argumentos nomeados (palavra-chave) da função.\n",
    "    \n",
    "    iter_ = int(iter_) # Se declarou iter_ em notação científica (1e3) ou float (1000.), converter\n",
    "    \n",
    "    # Inicializar j_hist como uma list ou um array Numpy. Recordar que não sabemos que tamanho terá\n",
    "    j_hist = [...]\n",
    "    \n",
    "    m, n = [...] # Obter m e n a partir das dimensões de X\n",
    "    \n",
    "    for k in [...]: # Iterar sobre o número máximo de \n",
    "        theta_iter = [...iterações ]# Declarar um theta para cada iteração, pois precisamos de a atualizar.\n",
    "        \n",
    "        for j in [...]: # Iterar sobre n.º de características\n",
    "            # Atualizar theta_iter para cada característica, de acordo com a derivada da função de custo\n",
    "            # Incluir a relação de formação alfa\n",
    "            # Cuidado com as multiplicações matriciais, a sua ordem e dimensões\n",
    "            theta_iter[j] = theta[j] - [...]\n",
    "            \n",
    "        theta = theta_iter\n",
    "            \n",
    "        cost = cost_function([...]) # Calcular o custo para a atual iteração theta\n",
    "            \n",
    "        j_hist[...] # Adicionar o custo da iteração atual ao histórico de custos\n",
    "        \n",
    "        # Comprovar se a diferença entre o custo da iteração atual e o custo da última iteração em valor \n",
    "        # absoluto são inferiores que a diferença mínima para declarar a convergência, e\n",
    "        if k > 0 and [...]:\n",
    "            print('Convergir na iteração n.º: ', k)\n",
    "            \n",
    "            break\n",
    "    else:\n",
    "        print('N.º máx. de iterações alcançado')\n",
    "        \n",
    "    return j_hist, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar a sua implementação, mais uma vez, utilizar vários valores de Theta, tanto corretos como valores cada vez mais\n",
    "afastados do mesmo, e verificar se eventualmente o modelo converge para o correto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Testar a sua implementação através da formação de um modelo no dataset sintético anteriormente criado.\n",
    "\n",
    "# Criar um theta inicial com um determinado valor.\n",
    "# Primeiro usar o valor theta correto, depois cada vez mais valores periféricos.\n",
    "# Finalmente, testar também a sua implementação com valores theta_ini aleatórios\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:') \n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1 \n",
    "e = 1e-3\n",
    "iter_ = 1e3 # Verificar se a sua função pode suportar valores de flutuação ou modificá-los.\n",
    "\n",
    "print('Hiper-parâmetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "t = time.time()\n",
    "j_hist, theta_final = gradient_descent([...]) \n",
    "\n",
    "print('Tempo de formação (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores da função de custo') \n",
    "print(j_hist[...])\n",
    "print('\\Custo final:') \n",
    "print(j_hist[...]) \n",
    "print('\\nTheta final:') \n",
    "print(theta_final)\n",
    "\n",
    "print('Valores verdadeiros de Theta e diferença com valores formados:') \n",
    "print(Theta_verd)\n",
    "print(theta_final - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representar a função de custo\n",
    "\n",
    "Representar graficamente o histórico da função de custo para comprovar a sua implementação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TOOD: Representar graficamente a função de custo vs. o n.º de iterações\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title('Função de custo') \n",
    "plt.xlabel('nº iterações') \n",
    "plt.ylabel('custo')\n",
    "\n",
    "plt.plot([...]) # Completar\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprovar completamente a implementação destas funções, modificar o dataset sintético original para verificar se a função \n",
    "de custo e a formação de gradient descent ainda a funcionar corretamente\n",
    "\n",
    "Por exemplo, modificar o número de exemplos e o número de características\n",
    "\n",
    "Acrescentar também uma vez mais um termo de erro ao Y. Neste caso, o Theta inicial e o final podem não corresponder exatamente, pois introduzimos erro ou “ruído” no dataset de formação.\n",
    "\n",
    "Finalmente, verificar todos os hiper-parâmetros da sua implementação. Utilizar vários valores de alfa, e, número de iterações, etc., e comprovar se os resultados são os esperados.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
