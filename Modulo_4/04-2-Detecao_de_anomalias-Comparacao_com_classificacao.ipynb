{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteção de anomalias: Comparação com classificação\n",
    "\n",
    "## O que vamos fazer?\n",
    "\n",
    "- Criar um dataset sintético para a deteção de anomalias com casos normais e anómalos.\n",
    "- Comparar a resolução do dataset com os métodos de deteção de anomalias de baixa probabilidade e classificação por SVM. \n",
    "- Avaliar ambos os métodos e representar graficamente os seus resultados.\n",
    "\n",
    "\n",
    "Os métodos de deteção de anomalias pela covariância da distribuição gaussiana e a baixa probabilidade de um evento (o método que usámos no exercício anterior) e por classificação são bastante semelhantes, principalmente se a classificação for feita com o SVM de kernel gaussiano, uma vez que ambos tentam modelar a mesma distribuição gaussiana sobre os dados.\n",
    "\n",
    "As suas principais diferenças só são percetíveis em algumas circunstâncias, por exemplo:\n",
    "- A distribuição dos exemplos normais não é gaussiana/normal, ou tem múltiplos centroides que não detetamos de antemão por agrupamento, por exemplo, e a classificação não é feita por SVM gaussiano.\n",
    "- Em dataset com um elevado número de dimensões, manter a distribuição normal dos dados é mais difícil.\n",
    "- A classificação, sendo um método de aprendizagem supervisionado, pode exigir uma percentagem de dados anómalos superior à de aprendizagem reforçada.\n",
    "\n",
    "Neste exercício vamos combinar ambos os métodos, que já resolveram em exercícios anteriores, para analisar os seus resultados e diferenças.\n",
    "\n",
    "Seguir as instruções abaixo para resolver o mesmo dataset por covariância da distribuição gaussiana e por SVM com kernel gaussiano, copiando as células de código de exercícios anteriores sempre que possível:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Usar esta célula para importar todas as livrarias necessárias\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do dataset original\n",
    "\n",
    "Vamos criar um dataset sintético seguindo os mesmos passos que no exercício de deteção de anomalias anterior. No entanto, iremos então criar 2 conjuntos de 3 subconjuntos diferentes de dados de formação, validação e teste, uma vez que para a deteção da covariância da distribuição gaussiana não atribuímos valores anómalos ao subset de formação e para a classificação por SVM se for necessário.\n",
    "\n",
    "\n",
    "Os passos que vamos então dar são:\n",
    "1. Criar um dataset de dados normais e outro de dados anómalos.\n",
    "1. Normalizar esses dados.\n",
    "1. Criar um subset de formação, validação e teste para resolver por covariância de distribuição Gaussiana, sem dados anómalos no subset de formação.\n",
    "1. Criar um conjunto de subsets de formação, validação e teste para resolver por SVM com kernel gaussiano, com dados anómalos em todos os subsets.\n",
    "1. Reordenar os dados aleatoriamente a partir dos 2 conjuntos de subsets.\n",
    "1. Representar graficamente os dados a partir dos 2 conjuntos de subsets.\n",
    "\n",
    "Portanto, completar as seguintes células de código, copiando o seu código de exercícios anteriores sempre que possível. No final, deve ter gerado, normalizado, dividido e reordenado as matrizes *X_cdg_train, X_cdg_cv, X_cdg_test, X_svm_train, X_svm_cv, X_svm_test* e os seus *Y* correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar dois datasets sintéticos independentes com dados normais e anómalos\n",
    "\n",
    "m = 500\n",
    "n = 2\n",
    "ratio_anomalos = 0.25    # Percentagem de dados anómalos vs dados normais, modificável\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os dados de ambos datasets com os mesmos parâmetros de normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Dividir os datasets nos subsets de formação, validação e teste para covariância de dist. gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir os datasets nos subsets de formação, validação e teste para classificação por SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar aleatoriamente os 2 conjuntos de subsets de formação, validação e teste individualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar os 3 subsets num gráfico 2D para covariância de distribuição gaussiana e classificação por SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução por deteção de anomalias por covariância da distribuição normal\n",
    "\n",
    "Para resolver o dataset para a covariância da distribuição normal, seguir os passos do exercício anterior, copiar as células correspondentes para as células seguintes, e ter o cuidado de utilizar os subsets adequados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modelar a distribuição gaussiana e obter mu e Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar múltiplos valores de epsilon e encontrar o melhor para classificar os dados como normais ou anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular a F1-score do modelo sobre o subset de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução por classificação por SVM\n",
    "\n",
    "Da mesma forma, seguir os passos do exercício SVM acima para classificar os dados em normais e anómalos por SVM, copiando as células correspondentes para as células seguintes sempre que possível, e ter o cuidado de utilizar os subsets adequados.\n",
    "\n",
    "Utilizar um kernel RBF com a função de Scikit-learn [OneClassSVM](https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html) e *ratio_anomalos* como parâmetro *nu*. Para regularizar o modelo, otimizar *gamma* com [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo de OneClassSVM e otimizar gamma no subset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular a F1-score do modelo sobre o subset de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação dos resultados de ambos os métodos\n",
    "\n",
    "Agora comparar ambos os métodos, mostrando F1-score e representando graficamente os seus resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Mostrar os resultados da F1-score de ambos os modelos\n",
    "\n",
    "print('F1-score da covariância da distribuição gaussiana:') \n",
    "print()\n",
    "print('F1-score da classificação por SVM:') \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representar os resultados de ambos os modelos Como os subsets de teste são diferentes em ambos os casos, nesta ocasião calcular os erros e acertos sobre os dados dos 3 subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar erros e acertos junto à distribuição e o corte de epsilon\n",
    "# para a covariância da distribuição gaussiana\n",
    "\n",
    "# Atribuir z = 1. para acerto e z = 0. para falha\n",
    "# Acerto: Y_test == Y_test_pred\n",
    "\n",
    "z_cdg = [...]\n",
    "# Representar o gráfico\n",
    "# Utilizar cores diferentes para os dados que acertou e os que falhou\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar erros e acertos no subset de teste junto à distribuição e o corte de epsilon\n",
    "# para a classificação por SVM\n",
    "\n",
    "# Atribuir z = 1. para acerto e z = 0. para falha\n",
    "# Acerto: Y_test == Y_test_pred\n",
    "z_svm = [...]\n",
    "\n",
    "# Representar o gráfico\n",
    "# Utilizar cores diferentes para os dados que acertou e os que falhou\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Que conclusões pode tirar? Que diferenças há entre ambos os métodos?*\n",
    "\n",
    "*BÓNUS: Consegue pensar numa forma de modificar os datasets iniciais para que os dois métodos obtenham resultados diferentes?*"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
