{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear: Comparação de valores de regularização\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Criar um dataset sintético para regressão linear multivariável com um termo de erro aleatório.\n",
    "- Formar 3 modelos diferentes de regressão linear neste dataset, com diferentes valores de *lambda*.\n",
    "- Comparar o efeito do valor de lambda sobre o modelo, a sua precisão e os seus resíduos graficamente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar um dataset sintético com erro para formação e teste final\n",
    "\n",
    "Vamos começar, como de costume, por criar um dataset sintético para regressão linear, com termo bias e termo de erro.\n",
    "\n",
    "Desta vez vamos criar 2 dataset, um para formação e outro para teste final, seguindo o mesmo padrão, embora com tamanhos diferentes. Vamos formar os modelos com o primeiro dataset e depois verificar com o segundo como se comportariam com dados que não “viram” anteriormente no processo de formação, que são completamente novos para eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um dataset sintéticos manualmente, com o termo de bias e o termo de erro \n",
    "\n",
    "m = 100\n",
    "n = 3\n",
    "\n",
    "X_train = [...]\n",
    "X_test = [...] # O tamanho do dataset do teste deve ser 25% do original.\n",
    "\n",
    "Theta_verd = [...] \n",
    "\n",
    "error = 0.25 \n",
    "\n",
    "Y_train = [...]\n",
    "Y_test = [...]\n",
    "\n",
    "# Comprovar os valores e dimensões dos vetores\n",
    "print('Theta a estimar e as suas dimensões') \n",
    "print()\n",
    "print()\n",
    "\n",
    "# Comprovar X_train, X_test, Y_train e Y_test \n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print() \n",
    "print() \n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:')\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar 3 modelos diferentes com diferentes valores de *lambda*\n",
    "\n",
    "Agora vamos formar 3 modelos diferentes com diferentes valores de *lambda*.\n",
    "\n",
    "Para o fazer, comece por copiar as suas células com o código que implementa a função de custo e o gradient descent regularizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copiar aqui as células ou o código para implementar 2 funções com a função de custo e o gradient.\n",
    "# descent regularizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos formar os modelos. Para o fazer, recordar que com Jupyter pode simplesmente modificar as células de código e as variáveis irão permanecer na memória.\n",
    "\n",
    "Assim, pode, por exemplo, modificar o nome das seguintes variáveis, mudando “1” para “2” e “3” e simplesmente reavaliar a célula para armazenar os resultados dos 3 modelos.\n",
    "\n",
    "Se encontrar alguma dificuldade, pode também copiar duas vezes a célula de código e ter 3 células para formar 3 modelos com nomes variáveis diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprovar a sua implementação através da formação de um modelo no dataset sintético anteriormente criado.\n",
    "\n",
    "# Criar um theta inicial com um determinado valor.\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:') \n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = [1e-3, 1e-1, 1e1] # Vamos usar 3 valores diferentes\n",
    "e = 1e-3\n",
    "iter_ = 1e3 # Comprovar se a sua função pode suportar valores de flutuação ou modificá-los.\n",
    "\n",
    "print('Hiper-parâmetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "t = time.time()\n",
    "# Usar lambda_[i],com i na gama [0, 1, 2] para cada modelo\n",
    "j_hist_1, theta_final_1 = gradient_descent([...]) \n",
    "\n",
    "print('Tempo de formação (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores da função de custo') \n",
    "print(j_hist_1[...])\n",
    "print('\\Custo final:') \n",
    "print(j_hist_1[...]) \n",
    "print('\\nTheta final:') \n",
    "print(theta_final_1)\n",
    "\n",
    "print('Valores verdadeiros de Theta e diferença com valores formados:') \n",
    "print(Theta_verd)\n",
    "print(theta_final_1 - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprovar graficamente o efeito de lambda sobre os modelos\n",
    "\n",
    "Agora vamos comprovar os 3 modelos entre si.\n",
    "\n",
    "Vamos começar por comprovar o custo final, uma representação da precisão dos mesmos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Mostrar o custo final dos 3 modelos:\n",
    "\n",
    "print('Custo final dos 3 modelos:')\n",
    "print(j_hist_1[...])\n",
    "print(j_hist_2[...])\n",
    "print(j_hist_3[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Como afeta um maior valor de **lambda** ao custo final neste dataset?*\n",
    "\n",
    "Vamos representar os dataset de formação e teste, para comprovar que seguem um padrão similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar X_train vs Y_train e X_test vs Y_test graficamente\n",
    "\n",
    "plt.figure(1) \n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Recordar usar cores diferentes\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "\n",
    "# Atreve-se? Procurar na documentação como criar uma legenda das diferentes séries e das suas cores.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora comprovar as previsões de cada modelo no dataset de formação, para ver até que ponto a linha se ajusta aos valores de formação em cada caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular previsões para cada modelo no X_train\n",
    "\n",
    "Y_train_pred1 = [...]\n",
    "Y_train_pred2 = [...]\n",
    "Y_train_pred3 = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para cada modelo, representar graficamente as suas previsões sobre X_train\n",
    "\n",
    "# Se obtiver um erro com outros gráficos do notebook, usar a linha abaixo ou deixar comentada.\n",
    "plt.figure(2)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "fig.suptitle([...])\n",
    "\n",
    "ax1.plot()\n",
    "ax1.scatter()\n",
    "\n",
    "ax2.plot()\n",
    "ax2.scatter()\n",
    "\n",
    "ax3.plot()\n",
    "ax3.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o dataset de formação tem um termo de erro de 25%, pode haver diferenças significativas entre os dados do dataset de formação e do dataset de teste.\n",
    "\n",
    "Vamos verificar o que acontece às previsões quando as representamos no dataset do teste, em dados que os modelos não tenham visto antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular previsões para cada modelo no X_test\n",
    "\n",
    "Y_test_pred1 = [...]\n",
    "Y_test_pred2 = [...]\n",
    "Y_test_pred3 = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para cada modelo, representar graficamente as suas previsões sobre X_test\n",
    "\n",
    "# Se obtiver um erro com outros gráficos do notebook, usar a linha abaixo ou deixar comentada.\n",
    "plt.figure(2)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "fig.suptitle([...])\n",
    "\n",
    "ax1.plot()\n",
    "ax1.scatter()\n",
    "\n",
    "ax2.plot()\n",
    "ax2.scatter()\n",
    "\n",
    "ax3.plot()\n",
    "ax3.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que acontece? Em alguns casos, dependendo dos parâmetros utilizados, pode ser mais ou menos fácil de apreciar.\n",
    "\n",
    "Quando o modelo tem um fator de regulação lambda baixo ou nulo, ajusta-se demasiado aos dados sobre os quais é formado, conseguindo uma curva muito apertada e a máxima precisão... nesse dataset.\n",
    "\n",
    "Contudo, na vida real, os dados sobre os quais não formámos o modelo podem chegar mais tarde e ter algumas pequenas variações sobre os dados originais.\n",
    "\n",
    "Em tal situação, preferimos um valor lambda mais elevado, o que nos permite ter uma maior precisão para os novos dados, mesmo que percamos alguma precisão para os dados do dataset de formação.\n",
    "\n",
    "Podemos, portanto, pensar na regularização como um estudante que tem as perguntas do exame antes:\n",
    "\n",
    "- Se depois receber essas perguntas, terá uma pontuação muito alta (ou precisão), uma vez que já “viu” as perguntas de antemão. \n",
    "- Se as perguntas forem diferentes, pode obter uma nota muito alta, dependendo de quão semelhantes são.\n",
    "- No entanto, se as perguntas forem totalmente diferentes, receberá uma nota muito baixa, porque não é que tenha estudado muito o assunto, mas sim que as suas notas eram altas só porque sabia o resultado de antemão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprovar os resíduos no subset de teste final\n",
    "\n",
    "Para este último ponto não lhe daremos mais instruções, mas será um desafio para si, mesmo que já o tenha resolvido anteriormente.\n",
    "\n",
    "Ousa calcular os resíduos para os 3 modelos e representá-los graficamente?\n",
    "\n",
    "Desta forma, poderá comparar os seus 3 modelos nos 2 datasets.\n",
    "\n",
    "Calcule-os tanto para os dataset de formação como de testes. Pode fazê-lo com células diferentes para poder apreciar as suas diferenças à vez.\n",
    "\n",
    "Conselhos:\n",
    "- Tenha cuidado com as escalas dos eixos X e Y ao fazer comparações.\n",
    "- Para poder vê-los ao mesmo tempo, pode criar 3 subgráficos horizontais, em vez de verticais, com “plt.subplots(1, 3)”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se não vir claramente estes efeitos nos seus conjuntos de dados, pode tentar modificar os valores iniciais:\n",
    "\n",
    "- Com um maior número de exemplos m, para que os modelos possam ser mais precisos.\n",
    "- Com um termo de erro maior, para que haja mais diferença e variação entre os exemplos.\n",
    "- Com um dataset de teste menor em relação ao dataset de formação, para que haja mais diferenças entre ambos os dataset (mais dados significa que os valores podem ser mais suavizados).\n",
    "- Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
