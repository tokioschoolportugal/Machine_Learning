{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recomendação\n",
    "\n",
    "O que vamos fazer?\n",
    "\n",
    "- Explorar a abordagem de filtros colaborativos\n",
    "- Criar um dataset para resolver por sistemas de recomendação \n",
    "- Implementar uma função de custo e descida de gradiente \n",
    "- Formar um modelo de recomendação por filtros colaborativos \n",
    "- Realizar previsões de recomendações\n",
    "- Voltar a formar o modelo incorporando novos valores \n",
    "- Recomendar exemplos semelhantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Usa esta célula para importar todas as livrarias necessárias\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar o dataset sintético\n",
    "\n",
    "Vamos criar um dataset sintético de novo, mas focado nos sistemas de recomendação, com algumas diferenças perante a regressão linear:\n",
    "- As variáveis previstas ou independentes *X* (de tamanho (m, n + 1)) que representam as características de cada exemplo, **não são conhecidas** de antemão.\n",
    "- O vetor $\\Theta$ (*Theta*) é 2D (de tamanho ($n_u$ + 1)), agora que representa os pesos ou coeficientes das características para cada utilizador. Novamente, não é conhecido de antemão.\n",
    "- O vetor *Y* é 2D (de tamanho (m, $n_u$)), agora representa a valorização para cada exemplo de cada utilizador.\n",
    "- O vetor *Y* irá conter tanto as valorizações “reais” que emitiu cada utilizador para cada película que valorizou, como, no final da formação, uma previsão das suas valorizações para recomendar uma película ou outra.\n",
    "- *R* será uma matriz “máscara” sobre *Y*, utilizada para indicar que valorizações de *Y* são as reais, emitidas por um utilizador e por tanto são aquelas a ter em conta para formar o modelo, e quais são apenas previsões.\n",
    "\n",
    "Um exemplo habitual são as recomendações de películas num portal de streaming de vídeo. Neste caso, um dataset teria estas características, p. ex.:\n",
    "- *m*: Nº de películas.\n",
    "- *n*: Nº de características de cada película e de coeficientes de cada utilizador.\n",
    "- $n_u$: Nº de utilizadores do portal.\n",
    "- $n_rr$ e $n_r$: Percentagem de valorizações de cada película por cada utilizador, e n.º de valorizações total, conhecidos de antemão.\n",
    "- *X*: Matriz 2D de características de cada película, tamanho (n.º de películas, n.º de características).\n",
    "- $\\Theta$: Matriz 2D de coeficientes de cada utilizador para cada película, tamanho (n.º de utilizadores, n.º de características).\n",
    "- *Y*: Matriz 2D de valorizações de cada utilizador para cada película, tamanho (n.º de utilizadores, n.º de películas).\n",
    "\n",
    "Para ter à mão, deixamos esta tabela rápida para consultar o tamanho de cada matriz:\n",
    "- *X*(m, n + 1)\n",
    "- $\\Theta$( $n_u$ , n + 1)\n",
    "- *Y*(m, $n_u$)\n",
    "\n",
    "Para não complicar mais a implementação, neste caso não pré-processaremos os dados, já que deveríamos pré-processar *X* e *Y*, que além disso deveríamos passar de uma escala p. ex. 0-5 estrelas a [0, 1].\n",
    "\n",
    "Na seguinte célula, seguir as instruções para gerar um dataset com as características necessárias para poder resolver por um filtro colaborativo de sistemas de recomendação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Criar um dataset com as características necessárias para um sistema de recomendação\n",
    "# Recordar que pode voltar a esta célula e modificar o tamanho do dataset em qualquer momento\n",
    "\n",
    "m = 10 # N.º de exemplos\n",
    "n = 4 # N.º de características de cada exemplo/utilizador\n",
    "n_u = 3 # N.º de utilizador\n",
    "n_rr = 0.5 # Percentagem de valorizações conhecidas de antemão\n",
    "\n",
    "# Criar um X com valores aleatórios e tamanho (m, n)\n",
    "# Inserir uma coluna de 1s na primeira posição\n",
    "X_verd = [...]\n",
    "X_verd = [...]\n",
    "\n",
    "# Criar um Theta_verd com valores aleatórios e tamanho (n_u, n + 1)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Criar um Y_verd multiplicando X_verd e Theta_verd\n",
    "Y_verd = [...]\n",
    "\n",
    "# Criar uma matriz R de zeros com tamanho (m, n_u)\n",
    "r = [...]\n",
    "count_r = round(n_rr * r.size) # nº de 1s em R\n",
    "while count_r:\n",
    "        # Gerar um int aleatório entre [0, m]\n",
    "    i = [...]\n",
    "        # Gerar um int aleatório entre [0, n_u]\n",
    "    j = [...]\n",
    "    \n",
    "    # Mudar esse índice de R a 1. se não se mudou antes, e diminuir em 1 o n.º de 1s em R\n",
    "    if not r[i,j]:\n",
    "        r[i,j] = 1.\n",
    "        count_r -= 1\n",
    "        \n",
    "# Contar os valores de R que não sejam 0.\n",
    "n_r = [...]\n",
    "\n",
    "# Gerar um Y com apenas as valorizações conhecidas usando R\n",
    "y = [...]\n",
    "\n",
    "print('Tamanho de X(m, n+1), Theta(n_u, n+1) e Y(m, n_u) verdadeiros:') \n",
    "print(X_verd.shape, Theta_verd.shape, Y_verd.shape)\n",
    "print('Tamanho de y e R conhecidas:') \n",
    "print(y.shape, r.shape)\n",
    "print('N.º de elementos de R, ou valorizações conhecidas:', n_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de custo e descida de gradiente\n",
    "\n",
    "Vamos implementar a função de custo regularizada e a descida de gradiente regularizado para a otimizar e formar o modelo de ML.\n",
    "\n",
    "Conceptualmente, quanto à formação do modelo por descida de gradiente, vamos seguir uns passos diferentes aos da regressão linear.\n",
    "\n",
    "Enquanto que na regressão linear eram conhecidos *Y* e *X*, e podíamos resolver iterativamente para $\\Theta$, nesta ocasião *X* nem é conhecida de antemão, já que habitualmente é impossível na prática conhecer ou ter anotadas de antemão todas as características de todos os exemplos ou películas.\n",
    "\n",
    "Além do mais, enquanto que se temos algumas valorizações por cada utilizador de algumas películas, habitualmente temos uma percentagem sob de todas as valorizações de cada utilizador para cada exemplo, pelo que *Y* é outra matriz variável não completamente conhecida de antemão, sem que a maioria dos seus campos irão estar vazios inicialmente.\n",
    "\n",
    "O nosso objetivo, neste caso, não será tanto resolver $\\Theta$ como resolver *Y* para obter todas as valorizações previstas de cada utilizador para \n",
    "cada exemplo.\n",
    "\n",
    "Por tanto, o algoritmo de formação será:\n",
    "\n",
    "1. Recompilar os exemplos e as valorizações nas matrizes *X*, $\\Theta$ e *Y*.\n",
    "1. Marcar as valorizações conhecidas na matriz dispersa *R*.\n",
    "1. Dadas *X* e *Y*, podemos prever $\\Theta$.\n",
    "1. Dadas $\\Theta$ e *Y*, podemos prever *X*.\n",
    "1. Estimar de forma iterativa *X* e $\\Theta$ em cada iteração porque a formação converta num custo mínimo.\n",
    "1. Quando dispusermos de mais valorizações, voltamos a formar o modelo adicionando-as a *Y* e marcando-as em *R*.\n",
    "\n",
    "Na seguinte célula, seguir as instruções para implementar a função de custo e gradient descent regularizados para um filtro colaborativo, seguindo as seguintes fórmulas:\n",
    "\n",
    "$$\n",
    "\\min\\limits_{\\theta^0, ..., \\theta^{n_u} \\\\ x^0, ..., x^{n_m}}J(x^0, ..., x^{n_m}, \\theta^0, ..., \\theta^{n_u}) = \\min\\limits_{\\theta^0, ..., \\theta^{n_u} \\\\ x^0, ..., x^{n_m}} (\\frac{1}{2} \\sum\\limits_{(i,j): r(i,j)=1} (\\theta^{jT} x^i - y^{i,j})^2 \\\\ + \\frac{\\lambda}{2} \\sum\\limits_{i=0}^{n_m} \\sum\\limits_{k=0}^n (x^i_k)^2 + \\frac{\\lambda}{2} \\sum\\limits_{j=0}^{n_u} \\sum\\limits_{k=0}^n (\\theta^j_k)^2) \\\\\n",
    "x^i_k := x^i_k - \\alpha (\\sum\\limits_{j: r(i,j) = 1} (\\theta^{j T} x^i - y^{i,j})\\theta^j_k + \\lambda x^i_k); \\\\\n",
    "\\theta^j_k := \\theta^j_k - \\alpha (\\sum\\limits_{i: r(i,j) = 1} (\\theta^{j T} x^i - y^{i,j}) x^i_k + \\lambda \\theta^j_k); j = 0 \\rightarrow \\lambda = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar a função de custo e formação por descida de gradiente para filtros colaborativos\n",
    "    \n",
    "def cost_function_collaborative_filtering_regularized(x, theta, y, r, lambda_=0.):\n",
    "    # DICA: Pode seguir estos passos:\n",
    "    # Cuidado com as dimensões, escolher a ordem adequada e se transpõe ou não\n",
    "    # Calcular a hipótese/previsão multiplicando X e Theta\n",
    "    # A esse valor, resta Y\n",
    "    # Para apenas formar sobre os valores conhecidos, multiplicar o resultado por R elemento a elemento\n",
    "    # Cuidado, a multiplicação elemento a elemento é uma função de Numpy diferente à multiplicação vetorial\n",
    "    # Elevar cada elemento ao quadrado\n",
    "    # Somar o resultado final\n",
    "    j = [...]\n",
    "    \n",
    "    # Calcular o fator de regularização para X\n",
    "    # Elevar cada elemento de X ao quadrado\n",
    "    # Somar todos os elementos na matriz 2D a um escalar\n",
    "    x_reg = [...]\n",
    "    # Calcular o fator de regularização para Theta\n",
    "    # Recordar não regularizar a primeira coluna\n",
    "    # Elevar ao quadrado todos os elementos restantes\n",
    "    # Somar a um escalar\n",
    "    theta_reg = [...]\n",
    "    \n",
    "    return 1/2 * (j + lambda_ * (x_reg + theta_reg))\n",
    "\n",
    "def gradient_descent_collaborative_filtering_regularized(x, theta, y, r, lambda_=0., alpha=1e-3, n_iter=1e3, e n_iter = int(n_iter) \n",
    "    # Converter n_iter a int para poder usar em range()\n",
    "                                                         \n",
    "    # Inicializar j_hist com o historial de valores da função de custo\n",
    "    j_hist = []\n",
    "    # Adicionar como primeiro valor de custo o custo da função de custo para os valores iniciais\n",
    "    j_hist.append(cost_function_collaborative_filtering_regularized([...]))\n",
    "                                                         \n",
    "    for l in range(n_iter):\n",
    "        # Inicializar uma theta y x para atualizar com o gradiente com arrays do mesmo tamanho dos originais\n",
    "        # e valores de vetor vazio (mais otimizado), zeros ou aleatórios\n",
    "        theta_grad = [...]\n",
    "        x_grad = [...]\n",
    "                                                         \n",
    "        for j in range(n_u):\n",
    "            # Calcular o gradiente para atualizar theta nesta iteração\n",
    "            # DICA: Pode seguir estes passos\n",
    "            # Multiplicar X pela fila j de theta transposta (não theta_grad)\n",
    "            # Resta a coluna j de Y\n",
    "            # Multiplicar o resultado pela fila j de R\n",
    "            # Multiplicar o resultado por X, cuidado com as dimensões e transposições se necessário\n",
    "            # Somar o resultado final para obter uma fila, com cuidado sobre o eixo que se realiza a soma\n",
    "            theta_grad[j,:] = [...]\n",
    "                                                         \n",
    "            # Para toda theta_grad exceto a primeira coluna, adicionar o termo de regularização\n",
    "            # lambda * (fila de) theta\n",
    "            if [...]:\n",
    "                theta_grad[j,:] += [...]\n",
    "                                                         \n",
    "\n",
    "        for i in range(m):\n",
    "            # Calcular o gradiente para atualizar X nesta iteração\n",
    "            # Seguir passos semelhantes ao gradiente de theta para implementar a função correspondente\n",
    "            # Somar o termo de regularização lambda * x\n",
    "            x_grad[i,:] = [...]\n",
    "                                                         \n",
    "        # Atualizar X e Theta restando alpha * gradientes\n",
    "        x -= alpha * x_grad\n",
    "        theta -= alpha * theta_grad\n",
    "                                                         \n",
    "        # Se necessitar, comprovar como se vão atualizando X e Theta\n",
    "        #print('\\nValores de X e Theta atualizados:')\n",
    "        #print(x)\n",
    "        #print(theta)\n",
    "                                                         \n",
    "        # Calcular o custo nesta iteração e adicionando ao historial de custos \n",
    "        j_cost = cost_function_collaborative_filtering_regularized([...]) j_hist.append(j_cost)\n",
    "                                                         \n",
    "        # Se não é a primeira iteração e a diferença absoluta entre o custo e o da iteração anterior\n",
    "        # menor que e, declara a convergência\n",
    "        if [...]:\n",
    "            print('Converge em iteração nº', l)\n",
    "                                                         \n",
    "            break\n",
    "    else:\n",
    "        print('Nº máx. de iterações {} alcançado'.format(n_iter))\n",
    "                                                         \n",
    "    return j_hist, x, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formação do modelo\n",
    "\n",
    "Uma vez implementadas as funções correspondentes, vamos formar o modelo.\n",
    "\n",
    "Para isso, completar a seguinte célula de código com passos equivalentes a outros modelos de exercícios prévios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo de sistema de recomendação por filtros colaborativos\n",
    "\n",
    "# Gerar uma X e Theta inicial com valores aleatórios e o mesmo tamanho que X_verd e Theta_verd\n",
    "x_init = [...]\n",
    "theta_init = [...]\n",
    "\n",
    "alpha = 1e-2 \n",
    "lambda_ = 0. \n",
    "e = 1e-3 \n",
    "n_iter = 1e4\n",
    "print('Hiper-parâmetros usados:')\n",
    "print('Alpha:', alpha, 'Lambda:', lambda_, 'Error:', e, 'Nº iter', n_iter)\n",
    "\n",
    "t0 = time.time()\n",
    "j_hist, x, theta = gradient_descent_collaborative_filtering_regularized(x_init, theta_init, y, r, lambda_, alp \n",
    "print('Duração do formação:', time.time() - t0)\n",
    "\n",
    "                                                                        \n",
    "print('\\nÚltimos 10 valores da função de custo:') \n",
    "print(j_hist[-10:])\n",
    "print('\\nError mínimo:') \n",
    "print(min(j_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos feito em ocasiões prévias, representar graficamente a evolução da função de custo para comprovar que a formação do modelo foi correto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente a função de custo da formação do modelo vs el nº de iterações\n",
    "plt.figure()\n",
    "\n",
    "# Representar o historial da função de custo\n",
    "plt.plot([...])\n",
    "\n",
    "# Adicionar um título, etiquetas em ambos os eixos do gráfico e uma grade\n",
    "[...]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realização de previsões de recomendações\n",
    "\n",
    "Uma vez formado o modelo, podemos resolver a matriz de recomendações *Y*, que contém como comentávamos tanto as valorizações emitidas pelos utilizadores como uma previsão da valorização de cada utilizador para cada exemplo.\n",
    "\n",
    "Recordar que utilizávamos a matriz *R* para marcar com um “1” as valorizações reais e com um “0” aquelas que foram previstas e não eram conhecidas de antemão.\n",
    "\n",
    "Para realizar uma previsão e recomendar exemplos aos utilizadores (p. ex. películas), seguir as instruções para completar a seguinte célula de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realizar previsões de exemplos para os utilizadores\n",
    "\n",
    "# Mostrar as valorizações da matriz Y\n",
    "print('Valorizações de Y:')\n",
    "print(y[:10,:10] * r[:10, :10]) # Limita o nº de filas e colunas de Y se necessário\n",
    "# No resultado, um valor de \"0.\" indica um “0.” nessa posição em R, ou que essa valorização inicial não é con\n",
    "\n",
    "# Calcular as previsões obtidas pelo modelo a partir de X e Theta\n",
    "# Recordar: Y = X * Theta^T\n",
    "y_pred = [...]\n",
    "\n",
    "print('\\nPrevisões de valorizações:') \n",
    "print(y_pred[:10,:10])\n",
    "\n",
    "# Calcular os resíduos das previsões\n",
    "# Recordar que os resíduos são a diferença em valores absolutos entre o valor real conhecido e as previsões\n",
    "# Recordar calcular apenas quando a valorização inicial é conhecida, multiplicando os resíduos por R\n",
    "y_residuo = [...]\n",
    "\n",
    "print('\\nResíduos do modelo:') \n",
    "print(y_residuo[:10,:10])\n",
    "\n",
    "# Mostrar as previsões e valorizações iniciais de um utilizador dado\n",
    "jj = 1 # Escolher o n.º de utilizador ou índice entre 0 e n_u que quer\n",
    "\n",
    "print('\\nValorizações reais e previstas para o utilizador nº {}:'.format(jj + 1)) \n",
    "print(y_pred[:,jj])\n",
    "\n",
    "# Ordenar os índices dos exemplos que recomendaríamos a cada utilizador em função das suas valorizações\n",
    "# Recordar eliminar da lista as valorizações emitidas inicialmente pelo utilizador\n",
    "# Para as eliminar, pode multiplicar as previsões por (r[:,jj] == 0.)\n",
    "# Para extrair os índices ordenados de um array pode utilizar np.argsort()\n",
    "# Para reordenar os índices de maior a menor pode utilizar np.flip() \n",
    "print('\\nValorizações previstas para o utilizador nº {}:'.format(jj + 1)) print([...])\n",
    "\n",
    "y_pred_ord = [...]\n",
    "\n",
    "print('\\nÍndices dos exemplos a recomendar para o utilizador {}, em função das valorizações previstas:'.f print(y_pred_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voltar a formar incorporando novas valorizações\n",
    "\n",
    "Para voltar a formar este modelo incorporando novas valorizações dos utilizadores, apenas há que modificar a *Y* inicial com as novas valorizações e marcar com um “1” a posição na matriz *R*.\n",
    "\n",
    "Seguir as instruções da seguinte célula para incorporar 2 novas valorizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Incorporar 2 novas valorizações de utilizadores a um exemplo à sua escolha\n",
    "\n",
    "# Escolher um índice de utilizador e de exemplo\n",
    "i_1 = 2\n",
    "j_1 = 2\n",
    "i_2 = 3\n",
    "j_3 = 3\n",
    "\n",
    "# Escolher uma valorização. Habitualmente tomam valores entre [0, 2)\n",
    "y[...] = 1.\n",
    "y[...] = 1.\n",
    "\n",
    "# Marca as novas valorizações em R\n",
    "r[...] = 1.\n",
    "r[...] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora voltar a formar o modelo reexecutando a célula de formação do modelo e as células seguintes até à célula anterior. \n",
    "\n",
    "Comprovar como agora essas posições mostram a nova valorização e não uma previsão do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontrar exemplos e utilizadores similares\n",
    "\n",
    "Para encontrar a semelhança entre 2 elementos, podemos computar a distância euclídea entre ambos.\n",
    "\n",
    "A distância euclídea neste espaço n-dimensional representará a diferença acumulada entre os coeficientes desses elementos, igual que uma distância num plano 2D ou 3D é a diferença acumulada entre as coordenadas desses pontos.\n",
    "\n",
    "Encontrar exemplos e utilizadores similares seguindo as instruções da seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encontrar exemplos e utilizadores similares entre si\n",
    "\n",
    "# Calcular a semelhança entre os 4 primeiros exemplos (X)\n",
    "dist_ej = distance.cdist([...])\n",
    "\n",
    "print('Semelhança entre os 4 primeiros exemplos:') \n",
    "print(dist_ej)\n",
    "\n",
    "# Calcular a semelhança entre os 4 primeiros utilizadores (Theta)\n",
    "dist_us = distance.cdist([...])\n",
    "\n",
    "print('Semelhança entre os 4 primeiros utilizadores:') \n",
    "print(dist_us)\n",
    "\n",
    "# Calcular o exemplo mais semelhante ao primeiro\n",
    "i_ej_similar = [...] \n",
    "ej_similar = [...]\n",
    "\n",
    "print('Coeficientes do exemplo nº {} para os 5 primeiros utilizadores:'.format(0 + 1)) \n",
    "print(x[0,:5])\n",
    "print('O exemplo mais semelhante ao nº {} é o exemplo nº {}'.format(0 + 1, i_ej_similar)) \n",
    "print('Coeficientes do exemplo nº {} para os 5 primeiros utilizadores:'.format(i_ej_similar)) \n",
    "print(ej_similar[:5])\n",
    "\n",
    "# Calcular o utilizador mais semelhante ao primeiro\n",
    "i_us_similar = [...] \n",
    "us_similar = [...]\n",
    "\n",
    "print('Coeficientes do utilizador nº {} para os 5 primeiros exemplos:'.format(0 + 1)) \n",
    "print(theta[0,:5])\n",
    "print('O utilizador mais semelhante ao nº {} é o utilizador nº {}'.format(0 + 1, i_us_similar)) \n",
    "print('Coeficientes do utilizador nº {} para os 5 primeiros exemplos:'.format(i_us_similar)) \n",
    "print(us_similar[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bónus: Comprovar que sucede se não temos um n.º mínimo de valorizações\n",
    "\n",
    "*O que sucede se não temos um nº mínimo de valorizações? E se há algum exemplo que não conta com nenhuma valorização de nenhum utilizador ou um utilizador que não valorizou nenhum exemplo?*\n",
    "\n",
    "*Acreditar que, nesse caso, poderíamos formar o modelo e obter resultados para esses exemplos e utilizadores?*\n",
    "\n",
    "Para o comprovar, pode p. ex. diminuir a percentagem de valorizações iniciais até um valor baixo, p. ex. um 25%, e comprovar que sucede com a evolução da função de custo da formação"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
