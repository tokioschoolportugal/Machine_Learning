{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de decisão: Comparação de árvores de regressão com regressão linear\n",
    "\n",
    "## O que vamos ver?\n",
    "- Comparar a precisão e o comportamento das árvores de decisão perante a regressão linear tradicional\n",
    "\n",
    "Em algumas ocasiões estima-se que as árvores de regressão possam não ter tanta precisão e cair em mais sobreajuste perante a regressão linear tradicional, principalmente com um alto nº de características.\n",
    "\n",
    "Neste exercício, vamos seguir os passos habituais para formar 2 modelos de regressão linear: uma árvore de decisão e um Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar todos os módulos necessários para esta célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar um dataset sintético\n",
    "\n",
    "Gerar um dataset sintético com um termo de erro algo grande e bastantes características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um conjunto de dados sintéticos para regressão linear com um termo de erro\n",
    "\n",
    "m = 1000\n",
    "n = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se o seu ambiente de trabalho não tem recursos suficientes, reduz o nº de características a 9, p. ex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "- Reordenar os dados aleatoriamente. \n",
    "- Normalizar.\n",
    "- Dividi-los em subconjuntos de formação e testes\n",
    "\n",
    "*Nota*: Mais uma vez, vamos utilizar a K-fold para a validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir os dataset e subset de formação e testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizar os modelos por validação cruzada\n",
    "\n",
    "- Formar um modelo por cada valor de regularização ou profundidade máx. a considerar. \n",
    "- Forma-os e avalia-os sobre uma divisão do subset de formação por K-fold.\n",
    "- Escolhe o modelo e a sua regularização ótima.\n",
    "\n",
    "Considerar uns parâmetros similares aos de exercícios passados:\n",
    "- Profundidade máxima no intervalo [1, 8]\n",
    "- Parâmetro de regularização L2 *alpha* no intervalo logarítmico [ [0, 0.1]: 0.1, 0.01, 0.001, 0.0001, etc.\n",
    "\n",
    "Pode-se copiar as células de exercícios anteriores e modificá-las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo diferente sobre um fold de K-fold diferente para a árvore de regressão e Lasso\n",
    "\n",
    "# Itera sobre os splits, forma os seus modelos e avalia-os sobre o subset do CV\n",
    "# As árvores de decisão e os modelos lineares de Lasso podem requerer um nº diferente de splits\n",
    "mejor_tree = [...] \n",
    "mejor_lasso = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo sobre o subset de teste\n",
    "\n",
    "Finalmente, vamos avaliar os melhores modelos de árvore de decisão e Lasso no subset de teste.\n",
    "\n",
    "Para o fazer, calcular as suas métricas MSE e a pontuação R^2 e representar graficamente as previsões do modelo vs. o subset de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com MSE e R^2 no subconjunto de teste para melhor árvore e Lasso\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Erro quadrático médio: %.2f', mse) \n",
    "print('Coeficiente de determinação: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, comprovar o seu possível desvio ou sobreajuste e precisão final representando graficamente os resíduos de ambos os modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente os resíduos de ambos os modelos\n",
    "\n",
    "residuos_tree = [...]\n",
    "residuos_lasso = [...]\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representar num gráfico de pontos, o subset de teste\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Há diferenças significativas entre ambos os modelos? O que ocorre se variamos o error ou o nº de características do dataset original, como respondem ambos os tipos de modelos?* \n",
    "\n",
    "Para o caso da árvore de regressão, talvez não tenhamos feito a comparação mais justa, posto que fiquem outros hiper-parâmetros que podemos modificar [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "\n",
    "## *Bonus*: Otimização de todos os hiper-parâmetros da árvore de decisão\n",
    "\n",
    "*Atreve-se a usar [sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) não apenas para otimizar max_depth, mas para todos os hiper-parâmetros da árvore de regressão?*\n",
    "\n",
    "Na página da documentação de GridSearchCV tem um exemplo que pode tomar como referência."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
