{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear: Exemplo sintético com Scikit-learn\n",
    "\n",
    "## O que vamos fazer?\n",
    "\n",
    "- Resolver um modelo de regressão linear multivariável usando o Scikit-learn.\n",
    "\n",
    "Após desenvolver uma implementação manual do algoritmo de regressão linear multivariável exclusivamente em Numpy, pudemos ver em \n",
    "profundidade os passos a seguir, como funciona o algoritmo matemático interno, e como todos os hiper-parâmetros o afetam.\n",
    "\n",
    "Tendo uma boa compreensão de como estes modelos ML funcionam, vamos ver como utilizá-los com as funções do framework do ML da \n",
    "Scikit-learn\n",
    "\n",
    "Neste exercício, terá um modelo em branco com os passos que seguimos nos exercícios anteriores, que terá de completar com o seu código seguindo esses passos, mas desta vez utilizando algumas funções Scikit-learn.\n",
    "\n",
    "Em cada célula iremos sugerir uma função Scikit-learn que poderá utilizar. Não lhe daremos mais informações sobre o assunto aqui, porque queremos que o procure na documentação: como funciona, os algoritmos que implementa (alguns deles serão ligeiramente diferentes dos que vimos no curso, não se preocupe uma vez que o importante é a base), argumentos, exemplos, etc.\n",
    "\n",
    "Parece óbvio, mas estou certo de que concordará connosco que a capacidade de saber como encontrar a informação relevante na documentação é muito importante, e muitas vezes pode custar-nos um pouco mais do que deveria :).\n",
    "\n",
    "Aproveite a oportunidade para mergulhar mais profundamente na documentação e descobrir aspetos interessantes do framework. Iremos continuar a trabalhar com ele em exercícios posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar de todos os módulos necessários para esta célula\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar um dataset sintético para regressão linear\n",
    "\n",
    "- Adicionar um termo de bias e de erro modificável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Criar um dataset sintético para regressão linear com Scikit-learn\n",
    "# Pode usar a função sklearn.datasets.make_regression()\n",
    "# Recordar de usar sempre um dado estado inicial aleatório para manter a reprodutibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizá-los.\n",
    "- Dividi-los em subsets de formação e testes.\n",
    "\n",
    "*Nota*:  Porque é que utilizamos 2 subsets de formação e testamos apenas uma vez, sem CV? Porque vamos utilizar a *k-fold* para a nossa validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente\n",
    "# Pode usar a função sklearn.utils.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os exemplos\n",
    "# Pode usar a classe sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*:  Esta escalada é equivalente à normalização básica que vimos durante o curso. Outra normalização mais conveniente em modelos mais avançados mas mais complexa de compreender seria a implementada em *sklearn.preprocessing.normalize.*\n",
    "\n",
    "Pode encontrar todas as classes e funções de pré-processamento disponíveis aqui: [Sklearn docs: 6.3. Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "\n",
    "E um gráfico de comparação:: [Compare the effect of different scalers on data with outliers](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir os dataset e os subset de formação e testes\n",
    "# Pode usar a função sklearn.model_selection.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo inicial\n",
    "\n",
    "- Formar um modelo inicial sobre o subset de formação sem regularização. \n",
    "- Comprovar a adequação do modelo.\n",
    "- Comprovar se há desvio ou sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para formar um modelo simples de regressão linear multivariável, pode utilizar a classe [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "\n",
    "Pode consultar um exemplo completo de formação: [Linear Regression Example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo de regressão linear mais simples sobre o subset de formação sem regularização.\n",
    "# Ajustar o termo intercept/bias e não normalizar as características, uma vez que já as normalizámos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprovar a adequação do modelo aplicado a este dataset. Para isso pode-se usar:\n",
    "- O coeficiente de determinação R^2 do método [LinearRegression.score()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score)\n",
    "- A função [sklearn.metrics.mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)\n",
    "- A função [sklearn.metrics.r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)\n",
    "\n",
    "Testar os 3 métodos para os conhecer melhor e ver as suas possíveis diferenças:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprovar a adequação do modelo, avaliando-o no subset de teste:\n",
    "# Comprovar as 3 métricas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fim de comprovar se pode haver desvio ou sobreajuste, podemos calcular, por exemplo, o erro médio ao quadrado nas previsões do subset de formação e do subset de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprovar se a avaliação sobre ambos os subsets é semelhante com o mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar a regularização ótima através de validação cruzada\n",
    "\n",
    "- Formar um modelo por cada valor de regularização a considerar.\n",
    "- Forma-os e avalia-os sobre uma divisão do subset de formação por K-fold. \n",
    "- Escolher o modelo e a sua regularização ótimos.\n",
    "\n",
    "Vamos agora utilizar um algoritmo de regressão linear mais complexo, o [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)  que nos permite definir um parâmetro de regularização L2\n",
    "\n",
    "Nesta função, este parâmetro é chamado *alpha*, embora não deva ser confundido com a ratio de aprendizagem.\n",
    "\n",
    "A regularização L2 é ligeiramente diferente do parâmetro *lambda* que vimos durante o curso, embora partilhem uma base comum. É a regularização implementada pela maioria dos algoritmos de Scikit-learn, embora pela sua complexidade não a vamos estudar aqui.\n",
    "\n",
    "Embora, claro, possa fazer mais investigação sobre o assunto, se quiser!\n",
    "\n",
    "Considerar uns parâmetros de regularização L2 no intervalo logarítmico [0, 0,1]: 0,1, 0,01, 0,001, 0,0001, 0,0001, etc. \n",
    "\n",
    "Pode ser guiado por esta ligação: [K-fold](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo diferente por cada alpha sobre um fold de K-fold diferente\n",
    "\n",
    "# Utilizar uma função Numpy para criar um espaço logarítmico de 5 valores entre [0, 0.,].\n",
    "alphas = [...]\n",
    "\n",
    "# Criar 5 splits de K-fold\n",
    "kf = [...]\n",
    "\n",
    "# Itera sobre os 5 splits, para os seus modelos e avalia-os no subset do CV gerado\n",
    "linear_models = [] \n",
    "best_model = None\n",
    "for train, cv in kf.split(X):\n",
    "    # Formar um modelo sobre o subset train\n",
    "    # Recordar estabelecer o parâmetro alfa correspondente, ajustar o bias e não normalizar\n",
    "    # Avaliar sobre o subset cv usando o seu método de score()\n",
    "    # Guardar o modelo com a melhor score na variável best_model e exibir o alfa do melhor modelo.\n",
    "    alpha = [...]\n",
    "    print('Regularização L2 usada:', alpha) \n",
    "    \n",
    "    linear_models[...] = [...]\n",
    "    \n",
    "    # Se o modelo for melhor do que o melhor modelo até agora.\n",
    "    best_model = [...]\n",
    "    print('Regularização L2 do melhor modelo até agora:', alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo finalmente sobre o subset de teste\n",
    "\n",
    "- Mostrar os coeficientes e intercept do melhor modelo. \n",
    "- Avaliar o melhor modelo sobre o subset de teste inicial. \n",
    "- Calcular os resíduos no subset de teste e representá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o melhor modelo sobre o subset de teste inicial\n",
    "\n",
    "# Mostrar os coeficientes e intercept do melhor modelo formado\n",
    "print('Coeficientes de intercept do modelo formado') print()\n",
    "    # Mostra o intercept como o primeiro coeficiente\n",
    "\n",
    "# Realizar as previsões sobre o subset de teste\n",
    "y_test_pred = [...]\n",
    "\n",
    "# Calcular a métrica de avaliação do modelo: erro quadrático médio e coeficiente de determinação.\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "\n",
    "print('Erro quadrático médio: %.2f' % mse) \n",
    "print('Coeficiente de determinação: %.2f' % r2_score)\n",
    "\n",
    "# Calcular os resíduos no subset de teste\n",
    "res = [...]\n",
    "\n",
    "# Representar graficamente\n",
    "plt.figure(1)\n",
    "\n",
    "# Completar com o seu código\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazer previsões sobre novos exemplos\n",
    "\n",
    "- Gerar um novo exemplo seguindo o mesmo padrão que o dataset original. \n",
    "- Normalizar as suas características.\n",
    "- Gerar uma previsão para esse exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO: Fazer previsões sobre um novo exemplo criado manualmente\n",
    "\n",
    "# Criar o novo exemplo\n",
    "X_pred = [...]\n",
    "\n",
    "# Normalizar as suas características\n",
    "X_pred = [...]\n",
    "\n",
    "# Gerar uma previsão para esse exemplo.\n",
    "y_pred = [...]"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
