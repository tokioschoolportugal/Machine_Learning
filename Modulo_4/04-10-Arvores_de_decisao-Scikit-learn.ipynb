{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de decisão: Scikit-learn\n",
    "\n",
    "## O que vamos fazer?\n",
    "- Formar um modelo de regressão linear por árvores de decisão \n",
    "- Detetar se ocorrem desvios ou sobreajustes no modelo \n",
    "- Otimizar hiper-parâmetros com validação cruzada \n",
    "- Avaliar no subconjunto de teste\n",
    "\n",
    "Vamos resolver um problema de regressão linear multivariável semelhante aos exercícios anteriores, mas desta vez utilizando uma árvore de decisão para a regressão linear.\n",
    "\n",
    "Um exemplo que pode utilizar como referência para este exercício: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importar todos os módulos necessários para esta célula"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar um dataset sintético\n",
    "\n",
    "Gerar um conjunto de dados sintéticos com um valor de erro algo grande e poucas características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um dataset sintéticos para regressão linear com um termo de erro notável.\n",
    "\n",
    "m = 1000\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente o dataset para assegurar que o termo de erro é suficientemente alto\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "- Reordenar os dados aleatoriamente. \n",
    "- Normalizar.\n",
    "- Dividi-los em subconjuntos de treino e testes.\n",
    "\n",
    "*Nota*: Mais uma vez, vamos utilizar a K-fold para a validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar os dados aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar os exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir os dataset e subset de formação e testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo inicial\n",
    "\n",
    "Vamos começar a explorar modelos de árvores de decisão para a regressão com um modelo inicial. \n",
    "\n",
    "Para isso, formar um modelo de [sklearn.tree.DecissionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)  sobre o subset de formação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar uma árvore de regressão no subconjunto de formação com profundidade máxima 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar agora a adequação do modelo, avaliando-o no subset de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com MSE e R^2 no subset de teste.\n",
    "\n",
    "y_test_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Erro quadrático médio: %.2f', mse) \n",
    "print('Coeficiente de determinação: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Acha que há desvio ou sobreajuste neste modelo?* Para o fazer, comparar a sua exatidão com a calculada no subset de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com MSE e R^2 agora no subconjunto de formação\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Erro quadrático médio: %.2f', mse) \n",
    "print('Coeficiente de determinação: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dissemos, as árvores de decisão tendem a sobreajustar, a ajustar demasiado os dados usados na sua formação e, por vezes, não poder prever bem os novos exemplos.\n",
    "\n",
    "Vamos comprovar graficamente, formando outro modelo com uma profundidade máxima muito maior de 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar outra árvore de regressão no subconjunto de formação com profundidade máxima 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com MSE e R^2 no subconjunto de formação\n",
    "\n",
    "y_train_pred = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Erro quadrático médio: %.2f', mse) \n",
    "print('Coeficiente de determinação: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar a precisão de formação deste modelo com o anterior (no subset de formação).\n",
    "\n",
    "*É maior ou menor ao aumentar a profundidade máxima da árvore?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos representar graficamente ambos os modelos, para comprovar se sofrem de desvio ou de sobreajuste. \n",
    "\n",
    "Para o fazer, pode guiar-se pelo exemplo anterior: [Decision Tree Regression](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente as previsões de ambos os modelos\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representar num gráfico de pontos, o subset de formação\n",
    "plt.scatter([...])\n",
    "# Representar num gráfico de pontos, o subset de teste, com uma cor diferente\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representar num gráfico de linhas as previsões de ambos os modelos, com cores diferentes e uma legenda\n",
    "# para os distinguir\n",
    "# Como eixo horizontal, usa um espaço linear de um grande número de elementos entre o valor máximo e mínimo de X.\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos, geralmente uma profundidade máxima demasiado pequena leva a um modelo com desvio, um modelo que não é capaz de se ajustar bem à curva, enquanto uma profundidade máxima demasiado alta leva a um modelo com sobreajuste, um modelo que se ajusta bem demais à curva, mas que não tem uma boa precisão em exemplos futuros.\n",
    "\n",
    "Assim, em termos de árvores de regressão, temos um hiper-parâmetro, a profundidade máxima, que devemos otimizar através de validação cruzada. Também há outros hiper-parâmetros, tais como o critério para medir a qualidade de uma divisão, a estratégia para criar essa divisão, o número \n",
    "mínimo de exemplos necessários para dividir um nó, etc., etc.\n",
    "\n",
    "Para simplificar, vamos começar a realizar a validação cruzada apenas para encontrar o valor ótimo da profundidade máxima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo diferente para cada valor de *max_depth* considerado sobre um fold diferente.\n",
    "\n",
    "# Valores de max_depth a considerar \n",
    "max_depths = list(range(1:8))\n",
    "print('Profundidades máx. a considerar:')\n",
    "print(max_depths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar o modelo sobre o subset de teste\n",
    "\n",
    "Finalmente, vamos avaliar o modelo sobre o subset de teste.\n",
    "\n",
    "Para o fazer, calcular as suas métricas de MSE e R^2 score e representar graficamente as previsões do modelo vs. o subset de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Avaliar o modelo com MSE e R^2 no subconjunto de teste.\n",
    "\n",
    "y_train_test = [...]\n",
    "\n",
    "mse = [...]\n",
    "r2_score = [...]\n",
    "print('Erro quadrático médio: %.2f', mse) \n",
    "print('Coeficiente de determinação: %.2f', r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente as previsões da melhor árvore do subset de teste\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Representar num gráfico de pontos, o subset de teste\n",
    "plt.scatter([...])\n",
    "\n",
    "# Representar num gráfico de linhas as previsões do modelo\n",
    "# Como eixo horizontal, usa um espaço linear de um grande número de elementos entre o valor máximo y min. de X_test\n",
    "x_axis = [...]\n",
    "\n",
    "plt.plot([...])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
