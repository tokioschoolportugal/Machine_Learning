{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística: Classificação multiclasse\n",
    "\n",
    "Uma vez implementada a formação completa de um modelo de regressão logística ou classificação binária (2 classes), vamos repetir o mesmo exemplo, mas para multiclasse\n",
    "\n",
    "## O que vamos fazer?\n",
    "\n",
    "- Criar um dataset sintético para regressão logística multiclasse.\n",
    "- Pré-processar os dados.\n",
    "- Formar o modelo sobre o subset de formação e comprovar a sua adequação.\n",
    "- Encontrar o parâmetro de regularização *lambda* ótimo por CV.\n",
    "- Fazer previsões sobre novos exemplos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar um dataset sintético para regressão logística multiclasse\n",
    "\n",
    "Vamos criar um dataset sintético de 3 classes para esta implementação completa.\n",
    "\n",
    "Para o fazer, criar um dataset sintético para regressão logística com termo de bias e erro manualmente (para ter *Theta_verd* disponível) com um modelo de código ligeiramente diferente do que usou no último exercício:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementar a função de ativação sigmoide\n",
    "\n",
    "Copiar a sua função de exercícios anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar a função sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a classificação multiclasse vamos calcular o *Y* de uma forma diferente: Y terá umas dimensões 2D de (classes x m), para representar todas as classes possíveis. Esta codificação de, por exemplo, [0, 0, 1] é chamada **one-hot encoding**.\n",
    "- Para cada exemplo e classe, calcular o sigmoide com *theta_verd* e *X..\n",
    "- Transformar os valores de *Y* para que sejam 0 e 1 no valor máx. do sigmoide.\n",
    "- Por último, transforma em 1 o valor da classe com em valor máx. do sigmoide e em 0 os valores do resto de classes.\n",
    "\n",
    "Para introduzir um termo de erro, recorrer todos os valores de *Y* e, com % de erro aleatório, modificar a classe desse exemplo a uma classe aleatória.\n",
    "\n",
    "Nota: tenha cuidado, como para simplificar a implementação não mudamos a classe de tal % de exemplos para outra diferente, mas escolhemos um ao acaso, isso não significa que teremos tal % de exemplos incorretos, mas que teremos classes de 1/n.º, pois será nossa probabilidade de escolher novamente o mesmo valor de *Y* para tal exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um dataset sintéticos, com o termo de bias e erro de forma manual\n",
    "# Já que vamos formar tantos modelos, gerar um dataset “pequeno” para que se formem rápido\n",
    "# Se necessitar, pode fazer mais pequeno ainda, ou se quiser mais precisão e um objetivo mais real, ampliá-lo\n",
    "m = 1000\n",
    "n = 2\n",
    "classes = 3\n",
    "\n",
    "Gerar um array 2D m x n com valores números aleatórios entre -1 e 1.\n",
    "# Inserir o termo de bias como primeira coluna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Gerar um array de theta 2D de classes x n + 1 valores aleatórios\n",
    "Theta_verd = [...]\n",
    "\n",
    "# E terá umas dimensões 2D de (classes x m)\n",
    "# Calcular com Y com o sigmoide e transformar os seus valores em 0 ou 1\n",
    "for c in range(classes): \n",
    "    Y[...] = sigmoid([...])\n",
    "    \n",
    "for j in range(m): \n",
    "    Y[...] = [...]\n",
    "    \n",
    "Para introduzir um termo de erro, recorrer todos os valores de Y e, com % de erro aleatório, modificar a\n",
    "# a classe escolhida desse exemplo por uma classe aleatória\n",
    "error = 0.15\n",
    "\n",
    "for j in range(m):\n",
    "    # Se um n.º à sorte é menor ou igual que erro\n",
    "    if [...]:\n",
    "        # Atribuir uma classe escolhida aleatoriamente\n",
    "        Y[...] = [...]\n",
    "        \n",
    "# Confirmar os valores e dimensões dos vetores\n",
    "print('Theta a estimar') \n",
    "print()\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processar os dados\n",
    "\n",
    "Tal como fizemos para a regressão linear, vamos pré-processar os dados completamente, seguindo os 3 passos habituais:\n",
    "\n",
    "- Reordená-los aleatoriamente. \n",
    "- Normalizá-los.\n",
    "- Dividi-los em subconjuntos de formação, CV e testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenar o dataset aleatoriamente\n",
    "\n",
    "Reorganizar os dados no dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordenar aleatoriamente o dataset\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Se preferir, pode usar a função de conveniência sklearn.utils.shuffle.\n",
    "# Usar um estado inicial aleatório de 42, de modo a manter a reprodutibilidade.\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeiras 10 filas e 5 colunas de X e Y:') \n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensões de X e Y:') \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar o dataset\n",
    "\n",
    "Implementar a função de normalização e normalizar o dataset de exemplos *X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normalizar o dataset com uma sua função de normalização.\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normalizar um dataset com exemplos X\n",
    "    \n",
    "    Argumentos posicionais:\n",
    "    x -- array 2D de Numpy com os exemplos, sem termo de bias\n",
    "    mu -- vetor 1D de Numpy com a média de cada característica/coluna\n",
    "    std -- vetor 1D de Numpy com o desvio típico de cada característica/coluna\n",
    "    \n",
    "    Devolver:\n",
    "    X norm -- array 2D de Numpy com os exemplos, com as suas características normalizadas \n",
    "    \"\"\"\n",
    "    return [...]\n",
    "\n",
    "# Encontrar a média e o desvio padrão das características de X (colunas), exceto a primeira (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:') \n",
    "print(X) \n",
    "print(X.shape)\n",
    "\n",
    "print('Média e desvio típico das características:') print(mu)\n",
    "print(mu.shape) \n",
    "print(std) \n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:') \n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std) # Normalizar apenas a coluna 1 e as colunas seguintes, não a 0.\n",
    "print(X_norm) \n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota*: Se tiver modificado a sua função de normalização para calcular e devolver os valores de *mu* e *std*, pode modificar esta célula para incluir o seu código personalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir os dataset e subset de formação, CV e testes\n",
    "\n",
    "Dividir o dataset *X* e *Y* em 3 subsets com o ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Se o seu n.º de exemplos for muito superior ou inferior, pode sempre modificar este ratio para outro, tal como 50/25/25 ou 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dividir o dataset X e Y nos 3 subset, de acordo com os ratios indicados.\n",
    "\n",
    "ratios = [60,20,20]\n",
    "print('Ratios:\\n', ratios, ratios[0] + ratios[1] + ratios[2])\n",
    "\n",
    "r = [0,0]\n",
    "# Dica: a função round() e o atributo x.shape podem ser-lhe úteis\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Dica: a função np.array_split() pode ser-lhe útil\n",
    "X_train, X_cv, X_test = [...]\n",
    "# Cuidado com as novas dimensões do Y!\n",
    "Y_train, Y_cv, Y_test = [...]\n",
    "\n",
    "print('Tamanhos dos subsets:') \n",
    "print(X_train.shape) \n",
    "print(Y_train.shape) \n",
    "print(X_cv.shape) print(Y_cv.shape) \n",
    "print(X_test.shape) \n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formar um modelo inicial em cada classe\n",
    "\n",
    "Para a classificação multiclasse, devemos formar um modelo diferente para cada classe. Portanto, se tivermos 3 classes, devemos formar 3 modelos diferentes.\n",
    "\n",
    "Cada modelo apenas irá considerar os valores da variável alvo relativamente à sua classe, classificar os exemplos como pertencentes à sua classe ou não (pertencentes ao resto).\n",
    "\n",
    "Para o fazer, apenas lhe iremos fornecer os valores de Y para essa classe ou coluna. P. ex.., Y = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "- Y para o modelo 1: [0, 0, 1]\n",
    "- Y para o modelo 2: [0, 1, 0]\n",
    "- Y para o modelo 3: [1, 0, 0]\n",
    "\n",
    "Tal como fizemos em exercícios anteriores, vamos formar modelos iniciais para verificar se a nossa implementação está correta:\n",
    "- Formar um modelo inicial sem regularização para cada classe.\n",
    "- Representar o histórico do seu custo para comprovar a sua evolução para cada modelo.\n",
    "- Se necessário, modificar quaisquer parâmetros e reformular os modelos. Irá usar esses parâmetros nos pontos seguintes.\n",
    "\n",
    "Copiar as células dos exercícios anteriores onde implementou a função de regularização de custos e gradient descent para regressão logística, e a célula onde formou o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copiar as células com as funções de custo e gradient descent regularizadas para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar os seus modelos no subset de formação sem regularizar.\n",
    "\n",
    "# Criar um theta inicial com um determinado valor.\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:') \n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1 \n",
    "lambda_ = 0. \n",
    "e = 1e-3 \n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-parâmetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "# Inicializar variáveis para armazenar o resultado de cada modelo com as dimensões apropriadas.\n",
    "# Cuidado: os modelos podem precisar de várias iterações até convergir de forma bastante díspar\n",
    "# Dar um tamanho ao j_train para armazenar até ao número máximo de iterações\n",
    "j_train_ini = [...] \n",
    "theta_train = [...]\n",
    "\n",
    "t = time.time()\n",
    "for c in [...]: # Iterar sobre o número de classes\n",
    "    print('\\nModelo para a classe nº:', c)\n",
    "    \n",
    "    theta_train = [...] # Cópia profunda do theta_ini para que não seja modificado\n",
    "    \n",
    "    t_model = time.time()\n",
    "    j_train_ini[...], theta_train[...] = regularized_logistic_gradient_descent([...]) \n",
    "    \n",
    "    print('Tempo de formação para o modelo (s):', time.time() - t_model)\n",
    "    \n",
    "print('Tempo de formação total (s):', time.time() - t)\n",
    "\n",
    "print('\\nCusto final do modelo para cada classe:') \n",
    "print()\n",
    "\n",
    "print('\\nTheta final do modelo para cada classe:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar a evolução da função de custo vs. o número de iterações para cada modelo\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Função de custo em cada classe')\n",
    "\n",
    "for c in range(classes): \n",
    "    plt.subplot(clases, 1, c + 1) \n",
    "    plt.xlabel('Iteraciçõess')\n",
    "    plt.ylabel('Custo em classe {}'.format(c)) \n",
    "    plt.plot(j_train_ini[...])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprovar a adequação dos modelos\n",
    "\n",
    "Verificar a precisão dos seus modelos e modificar os parâmetros para os formar de novo, se necessário.\n",
    "\n",
    "Recordar que se o seu dataset for “demasiado preciso” pode voltar à célula original e introduzir um termo de erro superior.\n",
    "\n",
    "Devido à complexidade de uma classificação multiclasse, não lhe iremos pedir para comprovar se os modelos podem estar a sofrer de desvio ou sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar o hiper-parâmetro *lambda* ótimo por CV\n",
    "\n",
    "Como fizemos em exercícios anteriores, iremos otimizar o nosso parâmetro de regularização através de validação cruzada para cada uma das classes e modelos.\n",
    "\n",
    "Para tal, para cada classe, iremos formar um modelo diferente para cada valor *lambda* a ser considerado no subset de formação, e avaliar o seu erro ou custo final no subset de CV.\n",
    "\n",
    "Mais uma vez, vamos representar graficamente o erro de cada modelo contra o valor *lambda* utilizado e implementar o código que irá escolher automaticamente o modelo mais ótimo para cada classe.\n",
    "\n",
    "Recordar de formar todos os seus modelos por igual.\n",
    "\n",
    "Por conseguinte, deve agora modificar o código na célula anterior para não formar um modelo, como antes, mas para formar um modelo para cada uma das classes, para cada um dos valores *lambda* a ser considerado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Formar um modelo para cada valor lambda diferente em X_train e avaliá-lo em X_cv\n",
    "# Os valores de lambda que considerámos anteriormente eram:\n",
    "# lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "# Se preferir, modificar o número de valores lambda para não formar tantos modelos e demorar tanto tempo.\n",
    "lambdas = [0., 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1e0, 3e0, 1e1]\n",
    "\n",
    "# Completar o código para formar um modelo diferente para cada classe e valor de lambda no X_train\n",
    "# Armazenar os thetas e erros/custos finais\n",
    "# Posteriormente, avaliar o seu custo total no subset da CV\n",
    "\n",
    "# Armazenar esta informação nas seguintes arrays\n",
    "# Ter cuidado com as suas dimensões necessárias\n",
    "j_train = [...]\n",
    "j_cv = [...]\n",
    "theta_cv = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representar graficamente o erro final para cada valor de lambda com um gráfico por classe\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "# Completar com o seu código\n",
    "for c in range(classes): \n",
    "    plt.subplot(classes, 1, c + 1)\n",
    "    \n",
    "    plt.title('Classe:', c) \n",
    "    plt.xlabel('Lambda') \n",
    "    plt.ylabel('Custo final') \n",
    "    plt.plot(j_train[...])\n",
    "    plt.plot(j_cv[...]) \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolher o melhor modelo para cada classe\n",
    "\n",
    "Copiar o código dos exercícios anteriores e modificá-lo para escolher o modelo mais preciso no subset de CV para cada classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escolher os modelos e os valores ótimos e o valor lambda, com o menor erro no subset do CV\n",
    "\n",
    "# Iterar sobre todas as combinações de theta e lambda e escolher o custo mais baixo no subset do CV\n",
    "\n",
    "j_final = [...] \n",
    "theta_final = [...] \n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar os modelos sobre o subset de teste\n",
    "Finalmente, vamos avaliar o modelo de cada classe sobre um subset de dados que não utilizámos para formação ou para a escolha de quaisquer hiper-parametros.\n",
    "\n",
    "Para tal, vamos calcular o erro ou custo total no subset de teste e comprovar graficamente os resíduos no mesmo:\n",
    "\n",
    "Recordar de usar apenas as colunas *Y* que cada modelo “veria”, pois classifica os exemplos de acordo com o facto de pertencerem ou não à sua classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular o erro do modelo no subset de teste usando a função de custo com as\n",
    "# thetas e lambdas correspondentes\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcular as previsões do modelo no subset de teste, calcular os resíduos e representá-los\n",
    "\n",
    "# Recordar de usar a função sigmoide para transformar as previsões.\n",
    "Y_test_pred = [...] \n",
    "\n",
    "resíduos = [...] \n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completar com o seu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bónus*: como no exercício anterior, para além dos resíduos, *porque não representar também graficamente todas as previsões no subset de teste para comprovar em quantas o nosso modelo acerta?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazer previsões sobre novos exemplos\n",
    "\n",
    "Com o nosso modelo formado, otimizado e avaliado, tudo o que resta é pô-lo a funcionar, fazendo previsões com novos exemplos.\n",
    "\n",
    "Para isso, vamos:\n",
    "\n",
    "- Gerar um novo exemplo seguindo o mesmo padrão que o dataset original.\n",
    "- Normalizar as suas características antes de poder fazer previsões a seu respeito.\n",
    "- Gerar uma previsão para este novo exemplo para cada uma das classes, ou seja, para cada um dos 3 modelos. \n",
    "- Escolher a classe final como a classe com o valor Y mais elevado após o sigmoide, uma vez que em alguns casos vários modelos podem querer classificar o exemplo na sua classe associada ao mesmo tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gerar um novo exemplo seguindo o padrão original, com termo de bias e erro aleatório.\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Para comparação, antes de normalizar os dados, utilizar o Theta_verd para ver qual seria a verdadeira classe associada.\n",
    "Y_verd = [...]\n",
    "\n",
    "# Normalizar as suas características (exceto o termo de bias) com as médias e desvios típicos originais\n",
    "X_pred = [...]\n",
    "\n",
    "# Gerar uma previsão para tal exemplo para cada modelo utilizando o sigmoide.\n",
    "Y_pred = [...]\n",
    "\n",
    "# Escolher a classe final como a de maior valor após o sigmoide e transformá-la para um vetor de 0s e 1s.\n",
    "Y_pred = [...]\n",
    "\n",
    "# Comparar a classe real associada a esse novo exemplo e a classe prevista\n",
    "print(‘A classe real do novo exemplo e a classe prevista.’)\n",
    "print(Y_verd)\n",
    "print(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
